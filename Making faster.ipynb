{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Motivation: separation of concerns and that the script currently is taking too long to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.meta import log, in_notebook\n",
    "from dataset.getting import get_raw_data, get_clean_network_data\n",
    "from dataset.cache import get_cached_data, test_same_df\n",
    "from dataset.cleaning import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[14:53:33] **9898 rows imported.**</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is same. Exiting...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[14:53:35] **7818 rows after filtering**: Required data.</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[14:53:35] **7781 rows after filtering**: Exclusion from visulization.</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[14:53:35] **7087 rows after filtering**: Unsure whether drag artist.</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[14:53:35] **7059 rows after filtering**: Full date in `Date` column.</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[14:53:35] **Cleaned up all names**.</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[14:53:35] **Fixed columns**: Renamed some columns and removed all unneccesary columns.</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[14:53:35] **Index has been reset**.</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _df = get_raw_data()\n",
    "\n",
    "    df_test = get_cached_data()\n",
    "\n",
    "    if test_same_df(_df, df_test):\n",
    "        print(\"Dataset is same. Exiting...\")\n",
    "        if not in_notebook():\n",
    "            exit()\n",
    "\n",
    "    _df.to_pickle('network-app/data/_df.pickle')\n",
    "    \n",
    "    df = get_clean_network_data(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Venue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Venue'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b2d3634fef10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_clean_network_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1930\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1940\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repositories/kallewesterling/dissertation/drag-data-1930s/dataset/getting.py\u001b[0m in \u001b[0;36mget_clean_network_data\u001b[0;34m(df, min_date, max_date, drop_cols, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdrop_cols\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/kallewesterling/dissertation/drag-data-1930s/dataset/filtering.py\u001b[0m in \u001b[0;36mfilter_data\u001b[0;34m(df, min_date, max_date, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_required_data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhas_required_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_required_data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**{df.shape[0]} rows after filtering**: Required data.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7546\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7547\u001b[0m         )\n\u001b[0;32m-> 7548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/kallewesterling/dissertation/drag-data-1930s/dataset/filtering.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_required_data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhas_required_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_required_data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**{df.shape[0]} rows after filtering**: Required data.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/kallewesterling/dissertation/drag-data-1930s/dataset/filtering.py\u001b[0m in \u001b[0;36mhas_required_data\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     14\u001b[0m         )\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# has_city = row['City'] or row['Normalized City']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mhas_venue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Venue\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_performer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_venue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Venue'"
     ]
    }
   ],
   "source": [
    "df = get_clean_network_data(_df, min_date=datetime.datetime(year=1930, month=1, day=1), max_date=datetime.datetime(year=1940, month=12, day=31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def group_dates(dates:list=[], delta=datetime.timedelta(days=14), dateformat='%Y-%m-%d'):\n",
    "    \"\"\"https://gist.github.com/kallewesterling/9a8d12ce073776ed52865bfb362ad073\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Chains dates together by looking for the delta between any given dates in a list\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    (A.) Provided that the delta is `days=14`,\n",
    "         the left side will generate the right side:\n",
    "            [                           [\n",
    "                1935-01-13,               [1935-01-13, 1935-01-26,\n",
    "                1935-01-26,                1935-02-11, 1935-02-05],\n",
    "                1935-02-11,\n",
    "                1935-02-05,\n",
    "                1935-04-01,               [1935-04-01, 1935-04-06]\n",
    "                1935-04-06\n",
    "            ]                           ]\n",
    "            \n",
    "    (B.) Provided that the delta is `days=3`,\n",
    "         the left side will generate the right side:\n",
    "            [                           [\n",
    "                1935-01-13,               [1935-01-13],\n",
    "                1935-01-26,               [1935-01-26],\n",
    "                1935-02-11,               [1935-02-11],\n",
    "                1935-02-05,               [1935-02-05],\n",
    "                1935-04-01,               [1935-04-01],\n",
    "                1935-04-06                [1935-04-06]\n",
    "            ]                           ]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    import re\n",
    "\n",
    "    try:\n",
    "        dates = sorted(set([datetime.datetime.strptime(x, dateformat) for x in dates]))\n",
    "    except ValueError as e:\n",
    "        date = re.search(r'''['\"](.*)['\"] does not match format''', str(e))\n",
    "        if date:\n",
    "            date = date.groups()[0]\n",
    "        raise ValueError(f'A date found in list that did not adhere to format (`{date}`). Needs to follow format `{dateformat}`.') from None\n",
    "\n",
    "    if isinstance(delta, int):\n",
    "        delta = timedelta(days=delta)\n",
    "\n",
    "    periods = []\n",
    "\n",
    "    for ix, date in enumerate(dates):\n",
    "        min_date = date - delta\n",
    "        max_date = date + delta\n",
    "\n",
    "        prev_date, next_date = None, None\n",
    "        start_chain, end_chain, in_chain, solo_date = None, None, None, None\n",
    "        prev_date_in_range, next_date_in_range = None, None\n",
    "\n",
    "        try:\n",
    "            if ix-1 >= 0:\n",
    "                prev_date = dates[ix-1]\n",
    "        except IndexError:\n",
    "            prev_date = None\n",
    "\n",
    "        try:\n",
    "            next_date = dates[ix+1]\n",
    "        except IndexError:\n",
    "            next_date = None\n",
    "\n",
    "        if next_date:\n",
    "            next_date_in_range = next_date >= min_date and next_date <= max_date\n",
    "\n",
    "        if prev_date:\n",
    "            prev_date_in_range = prev_date >= min_date and prev_date <= max_date\n",
    "\n",
    "        if all([next_date, prev_date, prev_date_in_range, next_date_in_range]):\n",
    "            # In the loop and in a chain (near previous date and next)\n",
    "            in_chain = True\n",
    "        elif all([next_date, prev_date, next_date_in_range]) and not prev_date_in_range:\n",
    "            # In the loop and beginning of a chain (not near previous date but near next)\n",
    "            start_chain = True\n",
    "        elif all([next_date, prev_date, prev_date_in_range]) and not next_date_in_range:\n",
    "            # In the loop and end of a chain (near previous date but not next)\n",
    "            end_chain = True\n",
    "        elif all([next_date, prev_date]) and not all([prev_date_in_range, next_date_in_range]):\n",
    "            # In the loop but solo date (not not near previous date nor next)\n",
    "            solo_date = True\n",
    "        elif next_date and next_date_in_range:\n",
    "            # In the loop but solo date (not not near previous date nor next)\n",
    "            start_chain = True\n",
    "        elif next_date:\n",
    "            solo_date = True\n",
    "        elif prev_date and prev_date_in_range:\n",
    "            end_chain = True\n",
    "        elif prev_date:\n",
    "            solo_date = True\n",
    "        elif not next_date and not prev_date:\n",
    "            solo_date = True\n",
    "        else:\n",
    "            raise RuntimeError('An unexpected error occurred.')\n",
    "\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "\n",
    "        if start_chain:\n",
    "            periods.append([date_str])\n",
    "\n",
    "        elif end_chain:\n",
    "            periods[len(periods)-1].append(date_str)\n",
    "\n",
    "        elif solo_date:\n",
    "            periods.append([date_str])\n",
    "\n",
    "        elif in_chain:\n",
    "            periods[len(periods)-1].append(date_str)\n",
    "\n",
    "    return periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./network-app/data/_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_venue_data(df=None, delta=datetime.timedelta(days=14), filter_unnamed=True):\n",
    "    if isinstance(df, type(None)):\n",
    "        raise RuntimeError(\"Needs DataFrame to proceed.\")\n",
    "    \n",
    "    venue_data = {}\n",
    "    venue_data_by_period = {}\n",
    "\n",
    "    for groups, rows in df.sort_values('Date').groupby(['Venue', 'Date']):\n",
    "        venue, date = groups\n",
    "        if filter_unnamed:\n",
    "            unique_performers = set(x for x in rows.Performer if not 'unnamed' in x.lower())\n",
    "        else:\n",
    "            unique_performers = set(x for x in rows.Performer)\n",
    "        if not len(unique_performers) > 1:\n",
    "            continue\n",
    "        if not venue in venue_data:\n",
    "            venue_data[venue] = set()\n",
    "        venue_data[venue].add(\n",
    "            (\n",
    "                date,\n",
    "                tuple(sorted(unique_performers)),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for venue in venue_data:\n",
    "        if len(venue_data[venue]) == 1:\n",
    "            continue\n",
    "\n",
    "        if not venue in venue_data_by_period:\n",
    "            venue_data_by_period[venue] = set()\n",
    "\n",
    "        dates = [x[0] for x in venue_data[venue]]\n",
    "        periods = group_dates(dates, delta=delta)\n",
    "        for period in periods:\n",
    "            performers = set()\n",
    "            for x in venue_data[venue]:\n",
    "                if x[0] in period:\n",
    "                    [performers.add(y) for y in x[1]]\n",
    "            \n",
    "            venue_data_by_period[venue].add((tuple(period), tuple(performers)))\n",
    "    \n",
    "    return venue_data_by_period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_from_venue_data(venue_data_by_period):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for venue, venue_data in venue_data_by_period.items():\n",
    "        for d in venue_data:\n",
    "            period, performers = d\n",
    "            for node1 in performers:\n",
    "                for node2 in [x for x in performers if not x == node1]:\n",
    "                    if not (node1, node2) in G.edges and not (node2, node1) in G.edges:\n",
    "                        G.add_edge(node1, node2, venues=set(), periods=set(), coLocated={})\n",
    "\n",
    "                    G.edges[(node1, node2)]['periods'].add(period)\n",
    "                    G.edges[(node1, node2)]['venues'].add(venue)\n",
    "                    if not venue in G.edges[(node1, node2)]['coLocated']:\n",
    "                        G.edges[(node1, node2)]['coLocated'][venue] = set()\n",
    "                    for date in period:\n",
    "                        G.edges[(node1, node2)]['coLocated'][venue].add(date)\n",
    "\n",
    "    for edge in G.edges:\n",
    "        for make_list in ['periods', 'venues']:\n",
    "            G.edges[edge][make_list] = sorted(list(G.edges[edge][make_list]))\n",
    "\n",
    "        for venue in G.edges[edge]['coLocated']:\n",
    "            G.edges[edge]['coLocated'][venue] = sorted(list(G.edges[edge]['coLocated'][venue]))\n",
    "\n",
    "        for ix, period in enumerate(G.edges[edge]['periods']):\n",
    "            G.edges[edge]['periods'][ix] = sorted(list(period))\n",
    "            \n",
    "    return G\n",
    "\n",
    "\n",
    "def unique_periods(G):\n",
    "    ''' Control function that allows for me to check how many unique periods have been assigned across the entire network's edges. '''\n",
    "    _ = set()\n",
    "    for edge in G.edges:\n",
    "        [_.add(tuple(period)) for period in G.edges[edge]['periods']]\n",
    "    return len(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networks = {}\n",
    "\n",
    "for days in [3,14,31,365]:\n",
    "    networks[days] = get_network_from_venue_data(get_venue_data(df, delta=datetime.timedelta(days=days), filter_unnamed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata is separate track too\n",
    "\n",
    "def get_meta_data(df, category=None):\n",
    "    meta_data = {\n",
    "        'performers': {},\n",
    "        'venues': {},\n",
    "        'cities': {},\n",
    "        'revues': {}\n",
    "    }\n",
    "\n",
    "    MAP = {\n",
    "        'performers': {\n",
    "            'cleaned_row_name': 'Performer',\n",
    "            'MAPPING': {\n",
    "                'comments': 'Comment on node: performer',\n",
    "                'legal_names': 'Legal name',\n",
    "                'alleged_ages': 'Alleged age',\n",
    "                'assumed_birth_years': 'Assumed birth year',\n",
    "                'images': 'Has image',\n",
    "                'exotic_dancer': 'Exotic/erotic/oriental dancer/Gypsy',\n",
    "                'fan_dancer': 'Fan dancer/Sally Rand',\n",
    "                'blackface': 'Blackface',\n",
    "                'sepia': 'Sepia',\n",
    "            }\n",
    "        },\n",
    "        'cities': {\n",
    "            'cleaned_row_name': 'City',\n",
    "            'MAPPING': {\n",
    "                'comments': 'Comment on node: city'\n",
    "            }\n",
    "        },\n",
    "        'venues': {\n",
    "            'cleaned_row_name': 'Venue',\n",
    "            'MAPPING': {\n",
    "                'comments': 'Comment on node: venue'\n",
    "            }\n",
    "        },\n",
    "        'revues': {\n",
    "            'cleaned_row_name': 'Revue',\n",
    "            'MAPPING': {\n",
    "                'comments': 'Comment on edge: revue'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ### No need to change anything below\n",
    "\n",
    "    for meta_data_category, d in MAP.items():\n",
    "        if category and not meta_data_category == category:\n",
    "            continue\n",
    "        \n",
    "        log(f'Fetching node meta information for {meta_data_category}...')\n",
    "        for ix, row in df.iterrows():\n",
    "            if not row[d['cleaned_row_name']] in meta_data[meta_data_category]:\n",
    "                meta_data[meta_data_category][row[d['cleaned_row_name']]] = {}\n",
    "\n",
    "            for key, column_name in d['MAPPING'].items():\n",
    "                if not key in meta_data[meta_data_category][row[d['cleaned_row_name']]]:\n",
    "                    meta_data[meta_data_category][row[d['cleaned_row_name']]][key] = []\n",
    "\n",
    "                if row[column_name]:\n",
    "                    source = row['Source']\n",
    "                    content = row[column_name]\n",
    "                    if isinstance(content, str) and content.lower() == 'true':\n",
    "                        content = True\n",
    "\n",
    "                    meta_data[meta_data_category][row[d['cleaned_row_name']]][key].append({\n",
    "                        'source': source,\n",
    "                        'content': content\n",
    "                    })\n",
    "    \n",
    "    return meta_data\n",
    "\n",
    "def get_meta(df=None, category=None):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        log('Building new clean data for node meta information...')\n",
    "        df = get_raw_data(verbose=False)\n",
    "        df = filter_data(df, max_date=None, min_date=None, verbose=False)\n",
    "        df = clean_data(df, drop_cols=['Venue'], verbose=False)\n",
    "    \n",
    "    all_meta = get_meta_data(df, category=category)\n",
    "    \n",
    "    if not category:\n",
    "        return all_meta\n",
    "    \n",
    "    return all_meta[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = get_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days, network in networks.items():\n",
    "    nx.set_node_attributes(network, metadata['performers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = get_clean_network_data(min_date=datetime.datetime(year=1930, month=1, day=1), max_date=datetime.datetime(year=1940, month=12, day=31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathpy as pp\n",
    "\n",
    "G = pp.TemporalNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_min = min([datetime.datetime.strptime(x, '%Y-%m-%d') for x in t_df.Date])\n",
    "edges = zip([x for x in df.Performer],\n",
    "    [x for x in df.Venue],\n",
    "    [(datetime.datetime.strptime(x, '%Y-%m-%d')-_min).days for x in t_df.Date]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in edges:\n",
    "    G.add_edge(edge[0], edge[1], str(edge[2]))\n",
    "    print('added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = pp.Node('node1')\n",
    "n2 = pp.Node('node2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(n1, n2, uid='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in G.edges:\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{x: y for x, y in nx.clustering(networks[14]).items() if y == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gcc = sorted(nx.connected_components(networks[14]), key=len, reverse=True)\n",
    "G0 = networks[14].subgraph(Gcc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thinking of more measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(func, count=10, **args):\n",
    "    ''' Meta function on which many other functions rely '''\n",
    "    from collections import Counter\n",
    "    c = Counter()\n",
    "    for x,y in func(**args).items():\n",
    "        c[x] = y\n",
    "        \n",
    "    return c.most_common()[:count]\n",
    "\n",
    "\n",
    "# In the following, we will use the following network:\n",
    "G = networks[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_triangles(G=None, count=10):\n",
    "    ''' Returns a Counter, sorted by the most common nodes with the most triangles '''\n",
    "    \n",
    "    func = nx.triangles\n",
    "    return get_top(func, count, G=G)\n",
    "\n",
    "\n",
    "get_top_triangles(G, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clustering(G=None, count=10):\n",
    "    ''' Returns a Counter, sorted by the most common nodes with the highest clustering coefficient\n",
    "        \n",
    "        What is a clustering coefficient?\n",
    "        \n",
    "        A measure of the degree to which nodes in a graph tend to cluster together, computed as\n",
    "        the proportion of connections among its neighbours which are actually realised compared\n",
    "        with the number of all possible connections.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    func = nx.clustering\n",
    "    return get_top(func, count=count, G=G)\n",
    "\n",
    "get_top_clustering(G, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average clustering for network\n",
    "\n",
    "nx.average_clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.all_pairs_node_connectivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import approximation as approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = {}\n",
    "for node1 in G.nodes:\n",
    "    for node2 in [x for x in G.nodes if not x == node]:\n",
    "        if not f'{node1};{node2}' and not f'{node2};{node1}' in _.keys():\n",
    "            _[f'{node1};{node2}'] = approx.local_node_connectivity(G, node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
