{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "class PropertyMap:\n",
    "    @property\n",
    "    def performer(self):\n",
    "        return self.get_prop('performer')\n",
    "\n",
    "    @property\n",
    "    def category(self):\n",
    "        return self.get_prop('category')\n",
    "    \n",
    "    @property\n",
    "    def venue(self):\n",
    "        return self.get_prop('venue')\n",
    "    \n",
    "    @property\n",
    "    def city(self):\n",
    "        return self.get_prop('city')\n",
    "    \n",
    "    @property\n",
    "    def revue_name(self):\n",
    "        return self.get_prop('revue_name')\n",
    "    \n",
    "    @property\n",
    "    def unsure_drag(self):\n",
    "        return self.get_prop('unsure_drag')\n",
    "    \n",
    "    @property\n",
    "    def legal_name(self):\n",
    "        return self.get_prop('legal_name')\n",
    "    \n",
    "    @property\n",
    "    def alleged_age(self):\n",
    "        return self.get_prop('alleged_age')\n",
    "    \n",
    "    @property\n",
    "    def assumed_birth_year(self):\n",
    "        return self.get_prop('assumed_birth_year')\n",
    "    \n",
    "    @property\n",
    "    def source(self):\n",
    "        return self.get_prop('source')\n",
    "    \n",
    "    @property\n",
    "    def eima(self):\n",
    "        return self.get_prop('eima')\n",
    "    \n",
    "    @property\n",
    "    def newspapers_search(self):\n",
    "        return self.get_prop('newspapers_search')\n",
    "    \n",
    "    @property\n",
    "    def fulton_search(self):\n",
    "        return self.get_prop('fulton_search')\n",
    "    \n",
    "    @property\n",
    "    def former_archive(self):\n",
    "        return self.get_prop('former_archive')\n",
    "    \n",
    "    @property\n",
    "    def comment(self):\n",
    "        return self.get_prop('comment')\n",
    "    \n",
    "    @property\n",
    "    def exclude(self):\n",
    "        return self.get_prop('exclude')\n",
    "    \n",
    "    @property\n",
    "    def quote(self):\n",
    "        return self.get_prop('quote')\n",
    "    \n",
    "    @property\n",
    "    def comment_performer(self):\n",
    "        return self.get_prop('comment_performer')\n",
    "    \n",
    "    @property\n",
    "    def comment_venue(self):\n",
    "        return self.get_prop('comment_venue')\n",
    "    \n",
    "    @property\n",
    "    def comment_city(self):\n",
    "        return self.get_prop('comment_city')\n",
    "    \n",
    "    @property\n",
    "    def comment_revue(self):\n",
    "        return self.get_prop('comment_revue')\n",
    "    \n",
    "    @property\n",
    "    def performer(self):\n",
    "        return self.get_prop('performer')\n",
    "    \n",
    "    @property\n",
    "    def performer_display(self):\n",
    "        return self.get_prop('performer_display')\n",
    "    \n",
    "    @property\n",
    "    def venue_display(self):\n",
    "        return self.get_prop('venue_display')\n",
    "    \n",
    "    @property\n",
    "    def city_display(self):\n",
    "        return self.get_prop('city_display')\n",
    "    \n",
    "    @property\n",
    "    def performer_safe(self):\n",
    "        return self.ensure_safe(self.get_prop('performer'))\n",
    "    \n",
    "    @property\n",
    "    def date(self):\n",
    "        return self.get_prop('date')\n",
    "    \n",
    "    @property\n",
    "    def row_num(self):\n",
    "        return self.get_prop('row_num')\n",
    "\n",
    "    \n",
    "class Row(PropertyMap):\n",
    "\n",
    "    def parse_row(self, row):\n",
    "        data = {}\n",
    "        data['row_num'], data['date'], data['category'], data['performer'], data['venue'], data['_city'], data['city'], data['_revue_name'], data['revue_name'], data['unsure_drag'], data['legal_name'], data['alleged_age'], data['assumed_birth_year'], data['source'], data['eima'], data['newspapers_search'], data['fulton_search'], data['former_archive'], data['comment'], data['exclude'], data['quote'], data['comment_performer'], data['comment_venue'], data['comment_city'], data['comment_revue'], *_ = row\n",
    "\n",
    "        ##### Fix date\n",
    "        data['date'] = data['date'].replace('?', '').strip()\n",
    "        orig_date = data['date']\n",
    "        data['date'] = self.fix_date(data['date'])\n",
    "\n",
    "        if not data['date'] and (data['performer'] or data['venue'] or data['city']):\n",
    "            pass # print(f'Warning: No date found ({orig_date}) but performer / venue / city found: {data[\"performer\"]} / {data[\"venue\"]} / {data[\"city\"]}')\n",
    "        \n",
    "        if not data['date'] or data['exclude']:\n",
    "            data = {}\n",
    "            return data\n",
    "\n",
    "        ##### Fix city\n",
    "        if not data['city']:\n",
    "            data['city'] = data['_city']\n",
    "            data['_city'] = ''\n",
    "\n",
    "        ##### Fix revue name\n",
    "        if not data['revue_name']:\n",
    "            data['revue_name'] = data['_revue_name']\n",
    "            data['_revue_name'] = ''\n",
    "        \n",
    "        ##### TODO: add filtering for names like —/-/–/\"n/a\"/etc\n",
    "        data['performer'] = data['performer'].replace(' & ', ' and ').replace('/', ' aka ').strip()\n",
    "        \n",
    "        for char in ['-', '–', '—', '?']:\n",
    "            while data['performer'].startswith(char):\n",
    "                data['performer'] = data['performer'][1:].strip()\n",
    "            \n",
    "            while data['venue'].startswith(char):\n",
    "                data['venue'] = data['venue'][1:].strip()\n",
    "            \n",
    "            while data['city'].startswith(char):\n",
    "                data['city'] = data['city'][1:].strip()\n",
    "                \n",
    "            while data['performer'].endswith(char):\n",
    "                print(data['performer'], 'shortened to', data['performer'][:-1])\n",
    "                data['performer'] = data['performer'][:-1].strip()\n",
    "            \n",
    "            while data['venue'].endswith(char):\n",
    "                print(data['venue'], 'shortened to', data['venue'][:-1])\n",
    "                data['venue'] = data['venue'][:-1].strip()\n",
    "            \n",
    "            while data['city'].endswith(char):\n",
    "                print(data['city'], 'shortened to', data['city'][:-1])\n",
    "                data['city'] = data['city'][:-1].strip()\n",
    "        \n",
    "        data['performer_display'] = data['performer']\n",
    "        data['venue_display'] = data['venue']\n",
    "        data['city_display'] = data['city']\n",
    "\n",
    "        for number, replacement in {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight', 9: 'nine', 0: 'zero'}.items():\n",
    "            data['performer'] = data['performer'].replace(str(number), replacement)\n",
    "            data['venue'] = data['venue'].replace(str(number), replacement)\n",
    "            data['city'] = data['city'].replace(str(number), replacement)\n",
    "        \n",
    "        data = {k: v for k, v in data.items() if v}\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def fix_date(self, date):\n",
    "        date = date.replace('?', '').strip()\n",
    "\n",
    "        try:\n",
    "            date = datetime.strptime(date, '%Y-%m-%d')\n",
    "        except ValueError as e:\n",
    "            try:\n",
    "                date = datetime.strptime(date.strip(), '%Y-%m')\n",
    "            except ValueError as e:\n",
    "                try:\n",
    "                    date = datetime.strptime(date.strip(), '%Y')\n",
    "                except ValueError as e:\n",
    "                    return ''\n",
    "                    # raise RuntimeError(date, 'cannot be interpreted:', e)\n",
    "\n",
    "        return date\n",
    "\n",
    "    def get_prop(self, name):\n",
    "        return self.parsed.get(name)\n",
    "    \n",
    "    def ensure_safe(self, string):\n",
    "        string = ''.join(re.findall(r'[a-zA-Z1-9-]', string)).lower()\n",
    "        while string.startswith('-'):\n",
    "            string = string[1:]\n",
    "        return string\n",
    "    \n",
    "    def __init__(self, row):\n",
    "        self.row = row\n",
    "        self.parsed = self.parse_row(row)\n",
    "    \n",
    "    @property\n",
    "    def has_basic_data(self):\n",
    "        if self.exclude:\n",
    "            return False\n",
    "        \n",
    "        if self.performer and self.venue:\n",
    "            return True\n",
    "        elif self.performer and self.city:\n",
    "            return True\n",
    "        elif self.venue and self.city:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "'''\n",
    "def fix_id_for_json(string):\n",
    "    string = ''.join(re.findall(r'[a-zA-Z1-9-]', string)).lower()\n",
    "    while string.startswith('-'):\n",
    "        string = string[1:]\n",
    "    return string\n",
    "'''\n",
    "\n",
    "def load_spreadsheet():\n",
    "    SPREADSHEET = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT0E0Y7txIa2pfBuusA1cd8X5OVhQ_D0qZC8D40KhTU3xB7McsPR2kuB7GH6ncmNT3nfjEYGbscOPp0/pub?gid=0&single=true&output=csv'\n",
    "    df = pd.read_csv(SPREADSHEET, encoding='utf8')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enesco? shortened to Enesco\n",
      "Enesco? shortened to Enesco\n",
      "Enesco? shortened to Enesco\n",
      "Enesco? shortened to Enesco\n",
      "Enesco? shortened to Enesco\n",
      "Jean — shortened to Jean \n",
      "Las Vegas, NV? shortened to Las Vegas, NV\n",
      "Chicago, IL? shortened to Chicago, IL\n",
      "Kemble? shortened to Kemble\n",
      "Hereford, UK? shortened to Hereford, UK\n",
      "San Antonio, TX? shortened to San Antonio, TX\n",
      "Chicago, IL? shortened to Chicago, IL\n",
      "Chicago, IL? shortened to Chicago, IL\n",
      "Chicago, IL? shortened to Chicago, IL\n",
      "Lima, OH? shortened to Lima, OH\n",
      "Lima, OH? shortened to Lima, OH\n",
      "Lima, OH? shortened to Lima, OH\n",
      "Lima, OH? shortened to Lima, OH\n",
      "Lima, OH? shortened to Lima, OH\n",
      "Lima, OH? shortened to Lima, OH\n",
      "Tucson, AZ? shortened to Tucson, AZ\n",
      "J. — shortened to J. \n"
     ]
    }
   ],
   "source": [
    "nodes = Counter()\n",
    "multi_edges = Counter()\n",
    "bipartite_edges = {\n",
    "    'performer-city': Counter()\n",
    "}\n",
    "edge_data = {}\n",
    "general_edge_comments = {}\n",
    "found = {}\n",
    "alleged_ages = {}\n",
    "assumed_birth_years = {}\n",
    "performer_comments = []\n",
    "city_comments = []\n",
    "venue_comments = []\n",
    "revue_comments = []\n",
    "\n",
    "df = load_spreadsheet()\n",
    "\n",
    "for row in df.fillna('').itertuples():\n",
    "    row = Row(row)\n",
    "    \n",
    "    if not row.has_basic_data:\n",
    "        continue\n",
    "        \n",
    "    if row.date:\n",
    "        date = row.date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Add nodes to list\n",
    "    if row.performer:\n",
    "        nodes[(row.performer, 'performer', row.ensure_safe(row.performer), row.performer_display)] += 1\n",
    "    if row.venue:\n",
    "        nodes[(f'{row.venue}-{row.city}', 'venue', row.ensure_safe(f'{row.venue}-{row.city}'), row.venue_display)] += 1\n",
    "    if row.city:\n",
    "        nodes[(row.city, 'city', row.ensure_safe(row.city), row.city_display)] += 1\n",
    "        \n",
    "    if row.alleged_age and row.performer:\n",
    "        alleged_ages[row.performer] = int(row.alleged_age)\n",
    "    elif row.alleged_age and not row.performer:\n",
    "        print('Warning: Found a stray alleged age with no performer assigned')\n",
    "        print(row.venue)\n",
    "        print(row.city)\n",
    "        print(row.alleged_age)\n",
    "        print('-------------')\n",
    "\n",
    "    if row.assumed_birth_year and row.performer:\n",
    "        assumed_birth_years[row.performer] = int(row.assumed_birth_year)\n",
    "    elif row.assumed_birth_year and not row.performer:\n",
    "        print('Warning: Found a stray alleged age with no performer assigned')\n",
    "        print(row.alleged_age)\n",
    "        print('-------------')\n",
    "\n",
    "    if (row.performer and (row.performer in alleged_ages and not row.performer in assumed_birth_years)):\n",
    "        print(f\"Warning: Found an age but not alleged birth year for performer {row.performer}.\")\n",
    "        print('-------------')\n",
    "\n",
    "    ########################################################\n",
    "    \n",
    "    # Add comments to lists of comments\n",
    "    if row.comment_performer and row.performer:\n",
    "        performer_comments.append((row.performer, row.comment_performer, row.source))\n",
    "    elif row.comment_performer and not row.performer:\n",
    "        print('Warning: Found a comment in the comment section for a performer with no name set:')\n",
    "        print(row.comment_performer)\n",
    "        print('----')\n",
    "\n",
    "    if row.comment_venue and row.venue:\n",
    "        venue_comments.append((f'{row.venue}-{row.city}', row.comment_venue, row.source))\n",
    "    elif row.comment_venue and not row.venue:\n",
    "        print('Warning: Found a comment in the comment section for a venue with no name set:')\n",
    "        print(row.comment_venue)\n",
    "        print('----')\n",
    "        \n",
    "    if row.comment_city and row.city:\n",
    "        city_comments.append((row.city, row.comment_city, row.source))\n",
    "    elif row.comment_city and not row.city:\n",
    "        print('Warning: Found a comment in the comment section for a city with no name set:')\n",
    "        print(row.comment_city)\n",
    "        print('----')\n",
    "\n",
    "    if row.comment_revue and row.revue_name:\n",
    "        revue_comments.append((row.revue_name, row.comment_revue, row.source))\n",
    "    elif row.comment_revue and not row.revue_name:\n",
    "        print('Warning: Found a comment in the comment section for a revue with no name set:')\n",
    "        print(row.comment_revue)\n",
    "        print('----')\n",
    "\n",
    "    ########################################################\n",
    "    \n",
    "    # Add edges to correct lists\n",
    "    if row.performer and row.venue and row.city:\n",
    "        node1 = row.performer\n",
    "        node2 = f'{row.venue}-{row.city}'\n",
    "        node3 = row.city\n",
    "        for edge in [\n",
    "            (node1, node2, row.ensure_safe(f'{node1}-{node2}')),\n",
    "            (node2, node3, row.ensure_safe(f'{node2}-{node3}'))\n",
    "        ]:\n",
    "            multi_edges[edge] += 1\n",
    "            \n",
    "            # Add to found dict\n",
    "            if not edge in found:\n",
    "                found[edge] = []\n",
    "                \n",
    "            found[edge].append(row.source)\n",
    "            \n",
    "            # Add to general_edge_comments dict\n",
    "            if row.comment:\n",
    "                if not edge[2] in general_edge_comments:\n",
    "                    general_edge_comments[edge[2]] = []\n",
    "\n",
    "                general_edge_comments[edge[2]].append({'comment': row.comment, 'source': row.source})\n",
    "\n",
    "            # Add edge_data here...\n",
    "            _edge_data = {\n",
    "                'date': date,\n",
    "                'row_num': row.row_num\n",
    "            }\n",
    "            edge_data[edge] = _edge_data\n",
    "            \n",
    "        # Set specific edge data\n",
    "        edge = (row.performer, f'{row.venue}-{row.city}', row.ensure_safe(f'{row.performer}-{row.venue}-{row.city}'))\n",
    "        if row.revue_name:\n",
    "            edge_data[edge]['revue_name'] = row.revue_name\n",
    "        else:\n",
    "            edge_data[edge]['revue_name'] = \"\"\n",
    "        \n",
    "        bipartite_edges['performer-city'][(row.performer, row.city)] += 1\n",
    "\n",
    "    elif row.venue and row.city:\n",
    "        node1 = f'{row.venue}-{row.city}'\n",
    "        node2 = row.city\n",
    "        edge = (node1, node2, row.ensure_safe(f'{node1}-{node2}'))\n",
    "\n",
    "        multi_edges[edge] += 1\n",
    "\n",
    "        # Add to found dict\n",
    "        if not edge in found:\n",
    "            found[edge] = []\n",
    "\n",
    "        found[edge].append(row.source)\n",
    "\n",
    "        # Add to general_edge_comments dict\n",
    "        if row.comment:\n",
    "            if not edge[2] in general_edge_comments:\n",
    "                general_edge_comments[edge[2]] = []\n",
    "\n",
    "            general_edge_comments[edge[2]].append({'comment': row.comment, 'source': row.source})\n",
    "\n",
    "\n",
    "        # Add edge_data here...\n",
    "        _edge_data = {\n",
    "            'date': date,\n",
    "            'row_num': row.row_num\n",
    "        }\n",
    "        if row.revue_name: _edge_data['revue_name'] = row.revue_name\n",
    "        edge_data[edge] = _edge_data\n",
    "\n",
    "    elif row.performer and row.city:\n",
    "        node1 = row.performer\n",
    "        node2 = row.city\n",
    "        edge = (node1, node2, row.ensure_safe(f'{row.performer}-{row.city}'))\n",
    "\n",
    "        multi_edges[edge] += 1\n",
    "\n",
    "        # Add to found dict\n",
    "        if not edge in found:\n",
    "            found[edge] = []\n",
    "\n",
    "        found[edge].append(row.source)\n",
    "\n",
    "        # Add to general_edge_comments dict\n",
    "        if row.comment:\n",
    "            if not edge[2] in general_edge_comments:\n",
    "                general_edge_comments[edge[2]] = []\n",
    "\n",
    "            general_edge_comments[edge[2]].append({'comment': row.comment, 'source': row.source})\n",
    "\n",
    "        # Add edge_data here...\n",
    "        _edge_data = {\n",
    "            'date': date,\n",
    "            'row_num': row.row_num\n",
    "        }\n",
    "        if row.revue_name: _edge_data['revue_name'] = row.revue_name\n",
    "        edge_data[edge] = _edge_data\n",
    "\n",
    "        bipartite_edges['performer-city'][(row.performer, row.city)] += 1\n",
    "        \n",
    "    elif row.performer and row.venue:\n",
    "        node1 = row.performer\n",
    "        node2 = f'{row.venue}-{row.city}'\n",
    "        edge = (node1, node2, row.ensure_safe(f'{node1}-{node2}'))\n",
    "\n",
    "        multi_edges[edge] += 1\n",
    "\n",
    "        # Add to found dict\n",
    "        if not edge in found:\n",
    "            found[edge] = []\n",
    "\n",
    "        found[edge].append(row.source)\n",
    "\n",
    "        # Add to general_edge_comments dict\n",
    "        if row.comment:\n",
    "            if not edge[2] in general_edge_comments:\n",
    "                general_edge_comments[edge[2]] = []\n",
    "\n",
    "            general_edge_comments[edge[2]].append({'comment': row.comment, 'source': row.source})\n",
    "\n",
    "        # Add edge_data here...\n",
    "        _edge_data = {\n",
    "            'date': date,\n",
    "            'row_num': row.row_num\n",
    "        }\n",
    "        if row.revue_name: _edge_data['revue_name'] = row.revue_name\n",
    "        edge_data[edge] = _edge_data\n",
    "        \n",
    "    else:\n",
    "        print('Warning: could not interpret data:')\n",
    "        print(row.performer)\n",
    "        print(row.venue)\n",
    "        print(row.city)\n",
    "        print('-------------')\n",
    "        exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_multi = nx.DiGraph()\n",
    "\n",
    "for edge in multi_edges:\n",
    "    source, target, edge_id = edge\n",
    "    weight = multi_edges[edge]\n",
    "    comments = []\n",
    "    \n",
    "    if edge_data[edge].get('revue_name'):\n",
    "        for revue_comment in set(list([x for x in revue_comments if x[0] == edge_data[edge]['revue_name']])):\n",
    "            _name, comment, comment_source = revue_comment\n",
    "            comments.append({'comment': comment, 'source': comment_source})\n",
    "    \n",
    "    general_comments = [y for x, y in general_edge_comments.items() if x == edge_id]\n",
    "    if len(general_comments) == 1:\n",
    "        general_comments = general_comments[0]\n",
    "    elif len(general_comments) > 1:\n",
    "        print('Warning: Seems like there may be general comments that are not captured here:')\n",
    "        print(general_comments[1:])\n",
    "        \n",
    "    G_multi.add_edge(source, target, date=edge_data[edge]['date'], comments=comments, weight=weight, found=found[edge], edge_id=edge_id, general_comments=general_comments, row_num=edge_data[edge]['row_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in nodes:\n",
    "    node, category, node_id, display = d\n",
    "    \n",
    "    if not node_id:\n",
    "        print(\"HAS NO ID\")\n",
    "        print(d)\n",
    "    \n",
    "    comments = []\n",
    "    \n",
    "    if category == 'venue':\n",
    "        # Process comments for venues\n",
    "        for d in [x for x in venue_comments if x[0] == node]:\n",
    "            _name, comment, source = d\n",
    "            comments.append({'comment': comment, 'source': source})\n",
    "    elif category == 'performer':\n",
    "        # Process comments for performers\n",
    "        for d in [x for x in performer_comments if x[0] == node]:\n",
    "            _name, comment, source = d\n",
    "            comments.append({'comment': comment, 'source': source})\n",
    "    elif category == 'city':\n",
    "        # Process comments for cities\n",
    "        for d in [x for x in city_comments if x[0] == node]:\n",
    "            _name, comment, source = d\n",
    "            comments.append({'comment': comment, 'source': source})\n",
    "    else:\n",
    "        print('Warning: I have no way to handle this category type of node.')\n",
    "\n",
    "    if comments:\n",
    "        nx.set_node_attributes(G_multi, {node: {'comments': comments}})\n",
    "    \n",
    "    if node in alleged_ages:\n",
    "        nx.set_node_attributes(G_multi, {node: {'alleged_age': alleged_ages[node]}})\n",
    "\n",
    "    if node in assumed_birth_years:\n",
    "        nx.set_node_attributes(G_multi, {node: {'assumed_birth_year': assumed_birth_years[node]}})\n",
    "\n",
    "    nx.set_node_attributes(G_multi, {node: {'display': display, 'category': category, 'node_id': node_id}})\n",
    "\n",
    "# Set degrees on all nodes\n",
    "nx.set_node_attributes(G_multi, dict(G_multi.in_degree()), 'indegree')\n",
    "nx.set_node_attributes(G_multi, dict(G_multi.out_degree()), 'outdegree')\n",
    "nx.set_node_attributes(G_multi, dict(G_multi.degree()), 'degree')\n",
    "\n",
    "# Set centrality measures on all nodes\n",
    "nx.set_node_attributes(G_multi, nx.betweenness_centrality(G_multi), 'centrality-betweenness')\n",
    "nx.set_node_attributes(G_multi, nx.eigenvector_centrality(G_multi, max_iter=1000), 'centrality-eigenvector')\n",
    "nx.set_node_attributes(G_multi, nx.degree_centrality(G_multi), 'centrality-degree')\n",
    "# nx.set_node_attributes(G_multi, nx.closeness_centrality(G_multi), 'centrality-closeness')\n",
    "# nx.set_node_attributes(G_multi, nx.current_flow_betweenness_centrality(G_multi, weight='weight'), 'centrality-current-flow')\n",
    "# nx.set_node_attributes(G_multi, nx.communicability_betweenness_centrality(G_multi), 'centrality-communicability')\n",
    "\n",
    "for node, attrs in G_multi.nodes.items():\n",
    "    G_multi.nodes[node]['1000x-betweenness-centrality'] = \"{:.15f}\".format(attrs['centrality-betweenness']*1000).rstrip('0')\n",
    "    G_multi.nodes[node]['1000x-eigenvector-centrality'] = \"{:.15f}\".format(attrs['centrality-eigenvector']*1000).rstrip('0')\n",
    "    G_multi.nodes[node]['1000x-degree-centrality'] = \"{:.15f}\".format(attrs['centrality-degree']*1000).rstrip('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./docs/data/drag-data-new.json', 'w+') as f:\n",
    "    json.dump(nx.node_link_data(G_multi), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
