{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import Markdown, display\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "\n",
    "def periodize_dates(dates:list=[], delta:datetime.timedelta=timedelta(days=14), dateformat='%Y-%m-%d'):\n",
    "    \"\"\"https://gist.github.com/kallewesterling/9a8d12ce073776ed52865bfb362ad073\"\"\"\n",
    "\n",
    "    try:\n",
    "        dates = sorted([datetime.datetime.strptime(x, dateformat) for x in dates])\n",
    "    except ValueError as e:\n",
    "        date = re.search(r'''['\"](.*)['\"] does not match format''', str(e))\n",
    "        if date:\n",
    "            date = date.groups()[0]\n",
    "        raise ValueError(f'A date found in list that did not adhere to format (`{date}`). Needs to follow format `{dateformat}`.') from None\n",
    "\n",
    "    if isinstance(delta, int):\n",
    "        delta = timedelta(days=delta)\n",
    "\n",
    "    periods = []\n",
    "\n",
    "    for ix, date in enumerate(dates):\n",
    "        min_date = date - delta\n",
    "        max_date = date + delta\n",
    "\n",
    "        prev_date, next_date = None, None\n",
    "        start_chain, end_chain, in_chain, solo_date = None, None, None, None\n",
    "        prev_date_in_range, next_date_in_range = None, None\n",
    "\n",
    "        try:\n",
    "            if ix-1 >= 0:\n",
    "                prev_date = dates[ix-1]\n",
    "        except IndexError:\n",
    "            prev_date = None\n",
    "\n",
    "        try:\n",
    "            next_date = dates[ix+1]\n",
    "        except IndexError:\n",
    "            next_date = None\n",
    "\n",
    "        if next_date:\n",
    "            next_date_in_range = next_date >= min_date and next_date <= max_date\n",
    "\n",
    "        if prev_date:\n",
    "            prev_date_in_range = prev_date >= min_date and prev_date <= max_date\n",
    "\n",
    "        if all([next_date, prev_date, prev_date_in_range, next_date_in_range]):\n",
    "            # In the loop and in a chain (near previous date and next)\n",
    "            in_chain = True\n",
    "        elif all([next_date, prev_date, next_date_in_range]) and not prev_date_in_range:\n",
    "            # In the loop and beginning of a chain (not near previous date but near next)\n",
    "            start_chain = True\n",
    "        elif all([next_date, prev_date, prev_date_in_range]) and not next_date_in_range:\n",
    "            # In the loop and end of a chain (near previous date but not next)\n",
    "            end_chain = True\n",
    "        elif all([next_date, prev_date]) and not all([prev_date_in_range, next_date_in_range]):\n",
    "            # In the loop but solo date (not not near previous date nor next)\n",
    "            solo_date = True\n",
    "        elif next_date and next_date_in_range:\n",
    "            # In the loop but solo date (not not near previous date nor next)\n",
    "            start_chain = True\n",
    "        elif next_date:\n",
    "            solo_date = True\n",
    "        elif prev_date and prev_date_in_range:\n",
    "            end_chain = True\n",
    "        elif prev_date:\n",
    "            solo_date = True\n",
    "        elif not next_date and not prev_date:\n",
    "            solo_date = True\n",
    "        else:\n",
    "            raise RuntimeError('An unexpected error occurred.')\n",
    "\n",
    "        if start_chain:\n",
    "            periods.append([date])\n",
    "\n",
    "        elif end_chain:\n",
    "            periods[len(periods)-1].append(date)\n",
    "\n",
    "        elif solo_date:\n",
    "            periods.append([date])\n",
    "\n",
    "        elif in_chain:\n",
    "            periods[len(periods)-1].append(date)\n",
    "            \n",
    "    return periods\n",
    "\n",
    "\n",
    "# Data clean up functions\n",
    "def has_required_data(row):\n",
    "    '''(internal) for use with DataFrame lambda function to ensure that any given row has the required data present'''\n",
    "    has_performer = row['Performer'] != '' or row['Normalized performer'] != '' or (row['Performer first-name'] != '' or row['Performer last-name']) != ''\n",
    "    # has_city = row['City'] or row['Normalized City']\n",
    "    has_venue = row['Venue'] != ''\n",
    "    if has_performer and has_venue:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def has_correct_date(row):\n",
    "    '''(internal) for use with DataFrame lambda function to ensure that any given row has a correct date present'''\n",
    "    return re.search(r'\\d{4}\\-\\d{2}\\-\\d{2}', row['Date']) != None\n",
    "\n",
    "\n",
    "def get_performer(row, null_value=''):\n",
    "    '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a performer's name (in an order of priority)'''\n",
    "\n",
    "    if row['Performer first-name'] and row['Performer last-name']:\n",
    "        return row['Performer first-name'] + ' ' + row['Performer last-name']\n",
    "    \n",
    "    for r in ['Normalized performer', 'Performer']:\n",
    "        if row[r]:\n",
    "            return row[r]\n",
    "    \n",
    "    return null_value\n",
    "\n",
    "    \n",
    "def get_city(row, null_value=''):\n",
    "    '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a city's name (in an order of priority)'''\n",
    "    for r in ['Normalized City', 'City']:\n",
    "        if row[r]:\n",
    "            return row[r]\n",
    "    \n",
    "    return null_value\n",
    "\n",
    "\n",
    "def get_unique_venue(row, null_value=''):\n",
    "    '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a venue's name (in an order of priority)'''\n",
    "    if row['Venue'] and row['City']:\n",
    "        return row['Venue'] + ' (' + row['City'] + ')'\n",
    "    \n",
    "    for r in ['Venue', 'City']:\n",
    "        if row[r]:\n",
    "            return row[r]\n",
    "\n",
    "    return null_value\n",
    "\n",
    "\n",
    "def get_source(row, null_value=''):\n",
    "    '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a source (in an order of priority)'''\n",
    "    for r in ['Source clean', 'Source']:\n",
    "        if row[r]:\n",
    "            return row[r]\n",
    "\n",
    "    return null_value\n",
    "\n",
    "\n",
    "def get_revue(row, null_value=''):\n",
    "    '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a revue's name (in an order of priority)'''\n",
    "    for r in ['Normalized Revue Name', 'Revue name']:\n",
    "        if row[r]:\n",
    "            return row[r]\n",
    "    \n",
    "    return null_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**7995 rows imported.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vT0E0Y7txIa2pfBuusA1cd8X5OVhQ_D0qZC8D40KhTU3xB7McsPR2kuB7GH6ncmNT3nfjEYGbscOPp0/pub?gid=0&single=true&output=csv')\n",
    "Markdown(f'**{df.shape[0]} rows imported.**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix basic stuff\n",
    "df.replace('—', '', inplace=True)\n",
    "df.replace('–', '', inplace=True)\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**7971 rows after filtering**: Exclusion from visulization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter\n",
    "df.drop(df[df['Exclude from visualization'] == True].index, inplace=True)\n",
    "Markdown(f'**{df.shape[0]} rows after filtering**: Exclusion from visulization.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**7494 rows after filtering**: Unsure whether drag artist."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter\n",
    "df.drop(df[df['Unsure whether drag artist'] == 'TRUE'].index, inplace=True)\n",
    "Markdown(f'**{df.shape[0]} rows after filtering**: Unsure whether drag artist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**5518 rows after filtering**: Required data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['has_required_data'] = df.apply(lambda row: has_required_data(row), axis=1)\n",
    "df.drop(df[df['has_required_data'] == False].index, inplace=True)\n",
    "Markdown(f'**{df.shape[0]} rows after filtering**: Required data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**5456 rows after filtering**: Full date in `Date` column."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['has_correct_date'] = df.apply(lambda row: has_correct_date(row), axis=1)\n",
    "df.drop(df[df['has_correct_date'] == False].index, inplace=True)\n",
    "Markdown(f'**{df.shape[0]} rows after filtering**: Full date in `Date` column.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "_Cleaned up all names_."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up names\n",
    "df['Performer'] = df.apply(lambda row: get_performer(row), axis=1)\n",
    "df['City'] = df.apply(lambda row: get_city(row), axis=1)\n",
    "df['Source'] = df.apply(lambda row: get_source(row), axis=1)\n",
    "df['Revue'] = df.apply(lambda row: get_revue(row), axis=1)\n",
    "df['Unique venue'] = df.apply(lambda row: get_unique_venue(row), axis=1)\n",
    "Markdown(f'_Cleaned up all names_.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "_Extracted node information_."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop *node* information - i.e. not relevant for edges\n",
    "node_information = {}\n",
    "node = {\n",
    "    'Legal name': None,\n",
    "    'Alleged age': None,\n",
    "    'Assumed birth year': None,\n",
    "    'Source': None\n",
    "}\n",
    "for ix, row in df.iterrows():\n",
    "    if row['Legal name'] or row['Alleged age'] or row['Assumed birth year']:\n",
    "        if row['Performer'] not in node_information:\n",
    "            node_information[row['Performer']] = []\n",
    "        \n",
    "        d = node\n",
    "        for cat in ['Legal name', 'Assumed birth year', 'Alleged age', 'Source']:\n",
    "            d[cat] = row[cat]\n",
    "            \n",
    "        node_information[row['Performer']].append(d)\n",
    "Markdown(f'_Extracted node information_.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "_Removed all unneccesary columns_:\n",
       " - Revue name\n",
       " -Normalized Revue Name\n",
       " -Legal name\n",
       " -Alleged age\n",
       " -Assumed birth year\n",
       " -Source clean\n",
       " -Category\n",
       " -2020-12-31 ID\n",
       " -Normalized City\n",
       " -Performer first-name\n",
       " -Performer last-name\n",
       " -Normalized performer\n",
       " -has_required_data\n",
       " -has_correct_date\n",
       " -Exclude from visualization\n",
       " -Unsure whether drag artist"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary information\n",
    "cols = ['Revue name', 'Normalized Revue Name', 'Legal name', 'Alleged age', 'Assumed birth year', 'Source clean', 'Category', '2020-12-31 ID', 'Normalized City', 'Performer first-name', 'Performer last-name', 'Normalized performer', 'has_required_data', 'has_correct_date', 'Exclude from visualization', 'Unsure whether drag artist']\n",
    "for col in cols:\n",
    "    try:\n",
    "        del df[col]\n",
    "    except KeyError:\n",
    "        pass # already gone\n",
    "Markdown(f'_Removed all unneccesary columns_:' + '\\n - ' + '\\n -'.join(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_venues = list(set([x for x in df['Unique venue']]))\n",
    "\n",
    "dfs = {}\n",
    "for venue in [x for x in all_venues]:\n",
    "    dfs[venue] = {'df': df[df['Unique venue'] == venue], 'count': 0}\n",
    "    for col in dfs[venue]['df'].columns:\n",
    "        if not col in ['Date', 'Performer', 'Unique venue', 'City', 'Source']:\n",
    "            del dfs[venue]['df'][col]\n",
    "    dfs[venue]['count'] = len(dfs[venue]['df'])\n",
    "    dfs[venue]['all_dates'] = sorted(list(set([x for x in dfs[venue]['df']['Date']])))\n",
    "    dfs[venue]['periodized_dates'] = periodize_dates(dfs[venue]['all_dates'], timedelta(days=14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['venue-link'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_connections = {}\n",
    "for venue in dfs:\n",
    "    if not venue in venue_connections:\n",
    "        venue_connections[venue] = {}\n",
    "    for period, dates in enumerate(dfs[venue]['periodized_dates'], start=1):\n",
    "        if not period in venue_connections[venue]:\n",
    "            venue_connections[venue][period] = {'dates': [], 'performers': []}\n",
    "        for date in dates:\n",
    "            venue_connections[venue][period]['dates'].append(date.strftime('%Y-%m-%d'))\n",
    "            for x, y in dfs[venue]['df'][dfs[venue]['df']['Date'] == date.strftime('%Y-%m-%d')].iterrows():\n",
    "                venue_connections[venue][period]['performers'].append(y['Performer'])\n",
    "        venue_connections[venue][period]['performers'] = list(set(venue_connections[venue][period]['performers']))\n",
    "        venue_connections[venue][period]['dates'] = sorted(list(set(venue_connections[venue][period]['dates'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "performer_connections = {}\n",
    "\n",
    "for venue, venue_connection in venue_connections.items():\n",
    "    for _, data in venue_connection.items():\n",
    "        for performer_out in data['performers']:\n",
    "            other_performers = [x for x in data['performers'] if not x == performer_out]\n",
    "            weight = len(data['dates'])\n",
    "            min_date = min([datetime.datetime.strptime(x, '%Y-%m-%d') for x in data['dates']])\n",
    "            max_date = max([datetime.datetime.strptime(x, '%Y-%m-%d') for x in data['dates']])\n",
    "            if not other_performers:\n",
    "                pass # Only one performer appeared in the period\n",
    "            for performer_in in other_performers:\n",
    "                if not performer_out in performer_connections:\n",
    "                    performer_connections[performer_out] = []\n",
    "                performer_connections[performer_out].append((performer_in, weight, venue, min_date, max_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "\n",
    "for source, connections in performer_connections.items():\n",
    "    for connection in connections:\n",
    "        target, weight, venue, min_date, max_date = connection\n",
    "        G.add_edges_from([(source, target, weight, {'venue': venue, 'min_date': min_date.strftime('%Y-%m-%d'), 'max_date': max_date.strftime('%Y-%m-%d')})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G=G, path='test.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
