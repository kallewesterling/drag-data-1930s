{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The script is set up: imports all the necessary packages and all the necessary functions to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'DAYSPANS': [3, 14, 31, 93, 186, 365]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown, clear_output\n",
    "# display(HTML(\"<style>.container {width: 80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        try:\n",
    "            if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "                return False\n",
    "        except AttributeError:\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def log(msg, color='green', verbose=True):\n",
    "    now = datetime.datetime.now().strftime('%H:%M%:%S')\n",
    "    if verbose and in_notebook():\n",
    "        return display(Markdown(f'<font color=\"{color}\">[{now}] {msg}</font>'))\n",
    "    elif verbose:\n",
    "        return print(f'[{now}]:\\n{msg}\\n\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "def slugify(value, allow_unicode=False, verbose=False):\n",
    "    init_value = str(value)\n",
    "    value = init_value\n",
    "    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "    value = re.sub(r'[^\\w\\s-]', '', value.lower())\n",
    "    value = re.sub(r'^(\\d+)', r'n\\1', value)\n",
    "    value = re.sub(r'[-\\s]+', '_', value).strip('-_')\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        log(f'Making slug from {init_value}: {value}')\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Central function (`get_raw_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_raw_data(verbose=True):\n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vT0E0Y7txIa2pfBuusA1cd8X5OVhQ_D0qZC8D40KhTU3xB7McsPR2kuB7GH6ncmNT3nfjEYGbscOPp0/pub?gid=0&single=true&output=csv')\n",
    "    \n",
    "    # Fix basic stuff\n",
    "    df.replace('—', '', inplace=True)\n",
    "    df.replace('—*', '', inplace=True)\n",
    "    df.replace('–', '', inplace=True)\n",
    "    df.fillna('', inplace=True)\n",
    "\n",
    "    log(f'**{df.shape[0]} rows imported.**', verbose=verbose)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "### Main filter function (`filter_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Main filter function\n",
    "\n",
    "def filter_data(df, min_date=None, max_date=None, verbose=True):\n",
    "    def has_required_data(row):\n",
    "        '''(internal) for use with DataFrame lambda function to ensure that any given row has the required data present'''\n",
    "        has_performer = row['Performer'] != '' or row['Normalized performer'] != '' or (row['Performer first-name'] != '' or row['Performer last-name']) != ''\n",
    "        # has_city = row['City'] or row['Normalized City']\n",
    "        has_venue = row['Venue'] != ''\n",
    "        if has_performer and has_venue:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def has_correct_date(row):\n",
    "        '''(internal) for use with DataFrame lambda function to ensure that any given row has a correct date present'''\n",
    "        return re.search(r'\\d{4}\\-\\d{2}\\-\\d{2}', row['Date']) != None\n",
    "    \n",
    "    def string_date(row):\n",
    "        return row['Date'].strftime('%Y-%m-%d')\n",
    "\n",
    "    df['has_required_data'] = df.apply(lambda row: has_required_data(row), axis=1)\n",
    "    df.drop(df[df['has_required_data'] == False].index, inplace=True)\n",
    "    log(f'**{df.shape[0]} rows after filtering**: Required data.', verbose=verbose)\n",
    "\n",
    "    # Filter\n",
    "    df.drop(df[df['Exclude from visualization'] == True].index, inplace=True)\n",
    "    df.drop(df[df['Exclude from visualization'] == 'TRUE'].index, inplace=True)\n",
    "    log(f'**{df.shape[0]} rows after filtering**: Exclusion from visulization.', verbose=verbose)\n",
    "    \n",
    "    # Filter\n",
    "    df.drop(df[df['Unsure whether drag artist'] == True].index, inplace=True)\n",
    "    df.drop(df[df['Unsure whether drag artist'] == 'TRUE'].index, inplace=True)\n",
    "    log(f'**{df.shape[0]} rows after filtering**: Unsure whether drag artist.', verbose=verbose)\n",
    "    \n",
    "    df['has_correct_date'] = df.apply(lambda row: has_correct_date(row), axis=1)\n",
    "    df.drop(df[df['has_correct_date'] == False].index, inplace=True)\n",
    "    log(f'**{df.shape[0]} rows after filtering**: Full date in `Date` column.', verbose=verbose)\n",
    "\n",
    "    if min_date or max_date:\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[(df['Date'] > min_date) & (df['Date'] < max_date)]\n",
    "        df['Date'] = df.apply(lambda row: string_date(row), axis=1)\n",
    "        log(f'**{df.shape[0]} rows after filtering**: Min and max date set.', verbose=verbose)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main clean function (`clean_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Main clean function\n",
    "\n",
    "def clean_data(df, drop_cols=[], verbose=True):\n",
    "    def get_performer(row, null_value=''):\n",
    "        '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a performer's name (in an order of priority)'''\n",
    "\n",
    "        first_name = row['Performer first-name']\n",
    "        last_name = row['Performer last-name']\n",
    "                    \n",
    "        if last_name and not first_name:\n",
    "            return last_name\n",
    "        \n",
    "        if first_name and last_name:\n",
    "            if not '—' in first_name and not '—' in last_name:\n",
    "                return f'{first_name} {last_name}'\n",
    "            \n",
    "            elif not '—' in last_name and '—' in first_name:\n",
    "                return last_name\n",
    "            \n",
    "            elif not '—' in first_name and '—' in last_name:\n",
    "                return first_name\n",
    "            \n",
    "        for r in ['Normalized performer', 'Performer']:\n",
    "            if row[r]:\n",
    "                return row[r]\n",
    "\n",
    "        return null_value\n",
    "\n",
    "\n",
    "    def get_city(row, null_value=''):\n",
    "        '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a city's name (in an order of priority)'''\n",
    "        for r in ['Normalized City', 'City']:\n",
    "            if row[r]:\n",
    "                return row[r]\n",
    "\n",
    "        return null_value\n",
    "\n",
    "\n",
    "    def get_unique_venue(row, null_value=''):\n",
    "        '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a venue's name (in an order of priority)'''\n",
    "        if row['Venue'] and row['City']:\n",
    "            return row['Venue'] + ' (' + row['City'] + ')'\n",
    "\n",
    "        for r in ['Venue', 'City']:\n",
    "            if row[r]:\n",
    "                return row[r]\n",
    "\n",
    "        return null_value\n",
    "\n",
    "\n",
    "    def get_source(row, null_value=''):\n",
    "        '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a source (in an order of priority)'''\n",
    "        for r in ['Source clean', 'Source']:\n",
    "            if row[r]:\n",
    "                g = re.search(r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)', row[r])\n",
    "                if not g:\n",
    "                    g = re.search(r'\\d{4}-\\d{2}-\\d{2}', row[r])\n",
    "                    if not g:\n",
    "                        return f\"{row[r]} ({datetime.datetime.strptime(row['Date'], '%Y-%m-%d').strftime('%B %d, %Y')})\"\n",
    "                return row[r]\n",
    "\n",
    "        return null_value,\n",
    "\n",
    "\n",
    "    def get_revue(row, null_value=''):\n",
    "        '''(internal) for use with DataFrame lambda function to return the cleaned-up version of a revue's name (in an order of priority)'''\n",
    "        for r in ['Normalized Revue Name', 'Revue name']:\n",
    "            if row[r]:\n",
    "                return row[r]\n",
    "\n",
    "        return null_value\n",
    "    \n",
    "    \n",
    "    # Clean up names\n",
    "    df['Performer'] = df.apply(lambda row: get_performer(row), axis=1)\n",
    "    df['City'] = df.apply(lambda row: get_city(row), axis=1)\n",
    "    df['Source'] = df.apply(lambda row: get_source(row), axis=1)\n",
    "    df['Revue'] = df.apply(lambda row: get_revue(row), axis=1)\n",
    "    df['Unique venue'] = df.apply(lambda row: get_unique_venue(row), axis=1)\n",
    "    log(f'**Cleaned up all names**.', verbose=verbose)\n",
    "\n",
    "    # Drop unnecessary information\n",
    "    for col in drop_cols:\n",
    "        try:\n",
    "            del df[col]\n",
    "        except KeyError:\n",
    "            pass # already gone\n",
    "\n",
    "    df = df.rename(columns={'Unique venue': 'Venue'})\n",
    "\n",
    "    log(f'**Fixed columns**: Renamed some columns and removed all unneccesary columns.', verbose=verbose)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a clean, basic dataset from Sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_clean_network_data(min_date=None, max_date=None, drop_cols=None, verbose=True):\n",
    "    ''' A \"collector\" function that runs through `get_raw_data`, `filter_data` and `clean_data` in that order and then resets the index.'''\n",
    "    \n",
    "    df = get_raw_data(verbose=verbose)\n",
    "    df = filter_data(df, min_date=min_date, max_date=max_date, verbose=verbose)\n",
    "    \n",
    "    if not drop_cols:\n",
    "        drop_cols = ['EIMA', 'Imported from former archive', 'Search (newspapers.com)', 'Search (fulton)', 'Venue', 'Revue name', 'Normalized Revue Name', 'Legal name', 'Alleged age', 'Assumed birth year', 'Source clean', 'Category', '2020-12-31 ID', 'Normalized City', 'Performer first-name', 'Performer last-name', 'Normalized performer', 'has_required_data', 'has_correct_date', 'Exclude from visualization', 'Blackface', 'Sepia', 'Fan dancer/Sally Rand', 'Exotic/erotic/oriental dancer/Gypsy', 'Has image', 'Address', 'Vaudeville Circuit/Circus', 'Edge Comment', 'Comment on node: performer', 'Comment on node: venue', 'Comment on node: city', 'Comment on edge: revue', 'Normalized Venue'] # , 'Unsure whether drag artist'\n",
    "    \n",
    "    df = clean_data(df, drop_cols, verbose=verbose)\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    log(f'**Index has been reset**.', verbose=verbose)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data generated\n",
    "\n",
    "Dataframe `df` generated, which can create good network data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a14d6290b410>:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = df.apply(lambda row: string_date(row), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Performer</th>\n",
       "      <th>City</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Source</th>\n",
       "      <th>Unsure whether drag artist</th>\n",
       "      <th>Revue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1934-05-19</td>\n",
       "      <td>Jack Mason</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Club Richman (New York, NY)</td>\n",
       "      <td>The Brooklyn Daily Eagle, May 19, 1934, 5</td>\n",
       "      <td></td>\n",
       "      <td>Jack Mason's Play Boy Revue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>1935-06-05</td>\n",
       "      <td>Teddy Hayes</td>\n",
       "      <td>Albany, NY</td>\n",
       "      <td>Echo Tavern (Albany, NY)</td>\n",
       "      <td>Times-Union (16) (June 05, 1935)</td>\n",
       "      <td></td>\n",
       "      <td>Jack Mason's Play Boy Revue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1935-10-09</td>\n",
       "      <td>Jack Mason</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>Club Piccadilly (Baltimore, MD)</td>\n",
       "      <td>The Baltimore Sun, October 9, 1935, 22</td>\n",
       "      <td></td>\n",
       "      <td>Jack Mason's Play Boy Revue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>1936-05-16</td>\n",
       "      <td>Lena Rivers</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>Dante's Inferno (Kansas City, MO)</td>\n",
       "      <td>The Kansas City Times, p. 7 (May 16, 1936)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>1936-10-23</td>\n",
       "      <td>Unnamed performer at Club Ambassador 1</td>\n",
       "      <td>Dayton, OH</td>\n",
       "      <td>Club Ambassador (Dayton, OH)</td>\n",
       "      <td>Dayton Daily News, p. 50 (October 23, 1936)</td>\n",
       "      <td></td>\n",
       "      <td>Fay Norman's Gay Boy Revue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>1936-10-23</td>\n",
       "      <td>Unnamed performer at Club Ambassador 3</td>\n",
       "      <td>Dayton, OH</td>\n",
       "      <td>Club Ambassador (Dayton, OH)</td>\n",
       "      <td>Dayton Daily News, p. 50 (October 23, 1936)</td>\n",
       "      <td></td>\n",
       "      <td>Fay Norman's Gay Boy Revue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>1937-03-11</td>\n",
       "      <td>Bobby Dell</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>Riviera Inn (Pittsburgh, PA)</td>\n",
       "      <td>The Mercury (Pottstown, Pennsylvania)11 Mar 19...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>1938-08-27</td>\n",
       "      <td>Bobby Allen</td>\n",
       "      <td>OH</td>\n",
       "      <td>J. R. Edwards Shows (OH)</td>\n",
       "      <td>All Boy Revue, The Billboard 50, no. 35, Augus...</td>\n",
       "      <td></td>\n",
       "      <td>Jack Leystan's All Boy Revue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>1938-12-30</td>\n",
       "      <td>Frances Hall</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>Kelly's Torch Club (Miami, FL)</td>\n",
       "      <td>The Miami News, December 30, 1938, 19</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>1939-02-24</td>\n",
       "      <td>Fritzie Feltz</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>Kelly's Torch Club (Miami, FL)</td>\n",
       "      <td>The Miami Herald, February 24, 1939, 46</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                               Performer             City  \\\n",
       "823   1934-05-19                              Jack Mason     New York, NY   \n",
       "1684  1935-06-05                             Teddy Hayes       Albany, NY   \n",
       "2347  1935-10-09                              Jack Mason    Baltimore, MD   \n",
       "2664  1936-05-16                             Lena Rivers  Kansas City, MO   \n",
       "3159  1936-10-23  Unnamed performer at Club Ambassador 1       Dayton, OH   \n",
       "3161  1936-10-23  Unnamed performer at Club Ambassador 3       Dayton, OH   \n",
       "3508  1937-03-11                              Bobby Dell   Pittsburgh, PA   \n",
       "4177  1938-08-27                             Bobby Allen               OH   \n",
       "4274  1938-12-30                            Frances Hall        Miami, FL   \n",
       "4515  1939-02-24                           Fritzie Feltz        Miami, FL   \n",
       "\n",
       "                                  Venue  \\\n",
       "823         Club Richman (New York, NY)   \n",
       "1684           Echo Tavern (Albany, NY)   \n",
       "2347    Club Piccadilly (Baltimore, MD)   \n",
       "2664  Dante's Inferno (Kansas City, MO)   \n",
       "3159       Club Ambassador (Dayton, OH)   \n",
       "3161       Club Ambassador (Dayton, OH)   \n",
       "3508       Riviera Inn (Pittsburgh, PA)   \n",
       "4177           J. R. Edwards Shows (OH)   \n",
       "4274     Kelly's Torch Club (Miami, FL)   \n",
       "4515     Kelly's Torch Club (Miami, FL)   \n",
       "\n",
       "                                                 Source  \\\n",
       "823           The Brooklyn Daily Eagle, May 19, 1934, 5   \n",
       "1684                   Times-Union (16) (June 05, 1935)   \n",
       "2347             The Baltimore Sun, October 9, 1935, 22   \n",
       "2664         The Kansas City Times, p. 7 (May 16, 1936)   \n",
       "3159        Dayton Daily News, p. 50 (October 23, 1936)   \n",
       "3161        Dayton Daily News, p. 50 (October 23, 1936)   \n",
       "3508  The Mercury (Pottstown, Pennsylvania)11 Mar 19...   \n",
       "4177  All Boy Revue, The Billboard 50, no. 35, Augus...   \n",
       "4274              The Miami News, December 30, 1938, 19   \n",
       "4515            The Miami Herald, February 24, 1939, 46   \n",
       "\n",
       "     Unsure whether drag artist                         Revue  \n",
       "823                               Jack Mason's Play Boy Revue  \n",
       "1684                              Jack Mason's Play Boy Revue  \n",
       "2347                              Jack Mason's Play Boy Revue  \n",
       "2664                                                           \n",
       "3159                               Fay Norman's Gay Boy Revue  \n",
       "3161                               Fay Norman's Gay Boy Revue  \n",
       "3508                                                           \n",
       "4177                             Jack Leystan's All Boy Revue  \n",
       "4274                                                           \n",
       "4515                                                           "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_clean_network_data(\n",
    "    min_date=datetime.datetime(year=1930, month=1, day=1),\n",
    "    max_date=datetime.datetime(year=1940, month=12, day=31),\n",
    "    verbose=False)\n",
    "\n",
    "# To illustrate, we show a 10-row random sample:\n",
    "df.sample(10).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performers_who_were_there(df, where=None, when=[]):\n",
    "    \"\"\"Returns a list of all the performers from any list of dates and venue\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    How this function works:\n",
    "    get_performers_who_were_there(df, 'Band Box (Syracuse, NY)', ['1935-03-29', '1935-04-05', '1935-04-12', '1935-04-19'])\n",
    "    \"\"\"\n",
    "    if not isinstance(when, list):\n",
    "        when = [when]\n",
    "    \n",
    "    all_values = []\n",
    "    for when in when:\n",
    "        if isinstance(when, datetime.datetime):\n",
    "            when = when.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "        selected_rows = df[(df['Date'] == when) & (df['Venue'] == where)]\n",
    "        \n",
    "        all_values.extend(selected_rows['Performer'])\n",
    "\n",
    "    return sorted(list(set(all_values)))\n",
    "\n",
    "\n",
    "def group_dates(dates:list=[], delta=datetime.timedelta(days=14), dateformat='%Y-%m-%d'):\n",
    "    \"\"\"https://gist.github.com/kallewesterling/9a8d12ce073776ed52865bfb362ad073\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Chains dates together by looking for the delta between any given dates in a list\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    (A.) Provided that the delta is `days=14`,\n",
    "         the left side will generate the right side:\n",
    "            [                           [\n",
    "                1935-01-13,               [1935-01-13, 1935-01-26,\n",
    "                1935-01-26,                1935-02-11, 1935-02-05],\n",
    "                1935-02-11,\n",
    "                1935-02-05,\n",
    "                1935-04-01,               [1935-04-01, 1935-04-06]\n",
    "                1935-04-06\n",
    "            ]                           ]\n",
    "            \n",
    "    (B.) Provided that the delta is `days=3`,\n",
    "         the left side will generate the right side:\n",
    "            [                           [\n",
    "                1935-01-13,               [1935-01-13],\n",
    "                1935-01-26,               [1935-01-26],\n",
    "                1935-02-11,               [1935-02-11],\n",
    "                1935-02-05,               [1935-02-05],\n",
    "                1935-04-01,               [1935-04-01],\n",
    "                1935-04-06                [1935-04-06]\n",
    "            ]                           ]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        dates = sorted([datetime.datetime.strptime(x, dateformat) for x in dates])\n",
    "    except ValueError as e:\n",
    "        date = re.search(r'''['\"](.*)['\"] does not match format''', str(e))\n",
    "        if date:\n",
    "            date = date.groups()[0]\n",
    "        raise ValueError(f'A date found in list that did not adhere to format (`{date}`). Needs to follow format `{dateformat}`.') from None\n",
    "\n",
    "    if isinstance(delta, int):\n",
    "        delta = timedelta(days=delta)\n",
    "\n",
    "    periods = []\n",
    "\n",
    "    for ix, date in enumerate(dates):\n",
    "        min_date = date - delta\n",
    "        max_date = date + delta\n",
    "\n",
    "        prev_date, next_date = None, None\n",
    "        start_chain, end_chain, in_chain, solo_date = None, None, None, None\n",
    "        prev_date_in_range, next_date_in_range = None, None\n",
    "\n",
    "        try:\n",
    "            if ix-1 >= 0:\n",
    "                prev_date = dates[ix-1]\n",
    "        except IndexError:\n",
    "            prev_date = None\n",
    "\n",
    "        try:\n",
    "            next_date = dates[ix+1]\n",
    "        except IndexError:\n",
    "            next_date = None\n",
    "\n",
    "        if next_date:\n",
    "            next_date_in_range = next_date >= min_date and next_date <= max_date\n",
    "\n",
    "        if prev_date:\n",
    "            prev_date_in_range = prev_date >= min_date and prev_date <= max_date\n",
    "\n",
    "        if all([next_date, prev_date, prev_date_in_range, next_date_in_range]):\n",
    "            # In the loop and in a chain (near previous date and next)\n",
    "            in_chain = True\n",
    "        elif all([next_date, prev_date, next_date_in_range]) and not prev_date_in_range:\n",
    "            # In the loop and beginning of a chain (not near previous date but near next)\n",
    "            start_chain = True\n",
    "        elif all([next_date, prev_date, prev_date_in_range]) and not next_date_in_range:\n",
    "            # In the loop and end of a chain (near previous date but not next)\n",
    "            end_chain = True\n",
    "        elif all([next_date, prev_date]) and not all([prev_date_in_range, next_date_in_range]):\n",
    "            # In the loop but solo date (not not near previous date nor next)\n",
    "            solo_date = True\n",
    "        elif next_date and next_date_in_range:\n",
    "            # In the loop but solo date (not not near previous date nor next)\n",
    "            start_chain = True\n",
    "        elif next_date:\n",
    "            solo_date = True\n",
    "        elif prev_date and prev_date_in_range:\n",
    "            end_chain = True\n",
    "        elif prev_date:\n",
    "            solo_date = True\n",
    "        elif not next_date and not prev_date:\n",
    "            solo_date = True\n",
    "        else:\n",
    "            raise RuntimeError('An unexpected error occurred.')\n",
    "\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "\n",
    "        if start_chain:\n",
    "            periods.append([date_str])\n",
    "\n",
    "        elif end_chain:\n",
    "            periods[len(periods)-1].append(date_str)\n",
    "\n",
    "        elif solo_date:\n",
    "            periods.append([date_str])\n",
    "\n",
    "        elif in_chain:\n",
    "            periods[len(periods)-1].append(date_str)\n",
    "\n",
    "    return periods\n",
    "\n",
    "\n",
    "def get_group_data(df, days=settings['DAYSPANS']):\n",
    "    data_dict = {}\n",
    "    \n",
    "    venue_count = len(df.groupby(\"Venue\"))\n",
    "    i = 1\n",
    "    for venue, row in df.groupby('Venue'):\n",
    "        i+=1\n",
    "        for num_days in days:\n",
    "            log(f'Generating group data for spans of {\", \".join([str(x) for x in days])} days.')\n",
    "            log(f'   [{i}/{venue_count}] processing venue {venue} (date span {num_days} days)...')\n",
    "            clear_output(wait=True)\n",
    "            all_dates = list(set(row.Date))\n",
    "            grouped_dates = group_dates(all_dates, delta=datetime.timedelta(days=num_days))\n",
    "            for ix, date_group in enumerate(grouped_dates, start=1):\n",
    "                if not venue in data_dict:\n",
    "                    data_dict[venue] = {}\n",
    "                if not f'grouped-by-{num_days}-days' in data_dict[venue]:\n",
    "                    data_dict[venue][f'grouped-by-{num_days}-days'] = {}\n",
    "                \n",
    "                revues = list(set([x for x in row.Revue if x]))\n",
    "                cities = list(set([x for x in row.City if x]))\n",
    "                \n",
    "                data_dict[venue][f'grouped-by-{num_days}-days'][f'date_group-{ix}'] = {\n",
    "                    'dates': date_group,\n",
    "                    'performers': get_performers_who_were_there(df, venue, date_group),\n",
    "                    'revues': revues,\n",
    "                    'cities': cities\n",
    "                }\n",
    "    log(f'Generated group data for {venue_count} venues.')\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get grouped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[23:39:34] Generated group data for 485 venues.</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_data_dict = get_group_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped data meta dataset\n",
    "\n",
    "Starts collecting a `metadata` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Sample of 10 random points in the dataset\n",
       "\n",
       "Each span (`3 days`, `14 days`, `31 days`, `93 days`, `186 days`, and `365 days`) has a `num_groups` column, a `max_span` column, and a `max performers` column."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_groups (#, delta: 3 days)</th>\n",
       "      <th>max_span (days, delta: 3 days)</th>\n",
       "      <th>max performers in a group (#, delta: 3 days)</th>\n",
       "      <th>group_member_counters for venue (#, delta: 3 days)</th>\n",
       "      <th>num_groups (#, delta: 14 days)</th>\n",
       "      <th>max_span (days, delta: 14 days)</th>\n",
       "      <th>max performers in a group (#, delta: 14 days)</th>\n",
       "      <th>group_member_counters for venue (#, delta: 14 days)</th>\n",
       "      <th>num_groups (#, delta: 31 days)</th>\n",
       "      <th>max_span (days, delta: 31 days)</th>\n",
       "      <th>...</th>\n",
       "      <th>max performers in a group (#, delta: 93 days)</th>\n",
       "      <th>group_member_counters for venue (#, delta: 93 days)</th>\n",
       "      <th>num_groups (#, delta: 186 days)</th>\n",
       "      <th>max_span (days, delta: 186 days)</th>\n",
       "      <th>max performers in a group (#, delta: 186 days)</th>\n",
       "      <th>group_member_counters for venue (#, delta: 186 days)</th>\n",
       "      <th>num_groups (#, delta: 365 days)</th>\n",
       "      <th>max_span (days, delta: 365 days)</th>\n",
       "      <th>max performers in a group (#, delta: 365 days)</th>\n",
       "      <th>group_member_counters for venue (#, delta: 365 days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tiny's Chateau (Pottstown, PA)</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{1: 7, 2: 4}</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>{1: 2, 2: 1}</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>{2: 2}</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>{2: 2}</td>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3</td>\n",
       "      <td>{3: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torch Club (Massillon, OH)</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>{5: 4, 7: 1}</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>{6: 1, 7: 1}</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>{6: 1, 7: 1}</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>{6: 1, 7: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>13</td>\n",
       "      <td>{13: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wonder Bar (Zanesville, OH)</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>{6: 2}</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>{8: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>{8: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>{8: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>{8: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capitol Theatre (Lancaster, PA)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States Theater</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twigg's Night Club (Akron, OH)</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{4: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{4: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>{4: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{4: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{4: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kedzie (Chicago) (Chicago, IL)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terrace Gardens (Jamestown, NY)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Javo Jungle Club (Pittsburgh, PA)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Club DeLisa (Chicago, IL)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   num_groups (#, delta: 3 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                11   \n",
       "Torch Club (Massillon, OH)                                     5   \n",
       "Wonder Bar (Zanesville, OH)                                    2   \n",
       "Capitol Theatre (Lancaster, PA)                                1   \n",
       "United States Theater                                          1   \n",
       "Twigg's Night Club (Akron, OH)                                 1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                 1   \n",
       "Terrace Gardens (Jamestown, NY)                                1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                              1   \n",
       "Club DeLisa (Chicago, IL)                                      1   \n",
       "\n",
       "                                   max_span (days, delta: 3 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                  1   \n",
       "Torch Club (Massillon, OH)                                      3   \n",
       "Wonder Bar (Zanesville, OH)                                     3   \n",
       "Capitol Theatre (Lancaster, PA)                                 0   \n",
       "United States Theater                                           0   \n",
       "Twigg's Night Club (Akron, OH)                                  1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                  0   \n",
       "Terrace Gardens (Jamestown, NY)                                 0   \n",
       "Javo Jungle Club (Pittsburgh, PA)                               0   \n",
       "Club DeLisa (Chicago, IL)                                       0   \n",
       "\n",
       "                                   max performers in a group (#, delta: 3 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                                2   \n",
       "Torch Club (Massillon, OH)                                                    7   \n",
       "Wonder Bar (Zanesville, OH)                                                   6   \n",
       "Capitol Theatre (Lancaster, PA)                                               1   \n",
       "United States Theater                                                         1   \n",
       "Twigg's Night Club (Akron, OH)                                                4   \n",
       "Kedzie (Chicago) (Chicago, IL)                                                1   \n",
       "Terrace Gardens (Jamestown, NY)                                               1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                             1   \n",
       "Club DeLisa (Chicago, IL)                                                     1   \n",
       "\n",
       "                                  group_member_counters for venue (#, delta: 3 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                          {1: 7, 2: 4}   \n",
       "Torch Club (Massillon, OH)                                              {5: 4, 7: 1}   \n",
       "Wonder Bar (Zanesville, OH)                                                   {6: 2}   \n",
       "Capitol Theatre (Lancaster, PA)                                               {1: 1}   \n",
       "United States Theater                                                         {1: 1}   \n",
       "Twigg's Night Club (Akron, OH)                                                {4: 1}   \n",
       "Kedzie (Chicago) (Chicago, IL)                                                {1: 1}   \n",
       "Terrace Gardens (Jamestown, NY)                                               {1: 1}   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                             {1: 1}   \n",
       "Club DeLisa (Chicago, IL)                                                     {1: 1}   \n",
       "\n",
       "                                   num_groups (#, delta: 14 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                  3   \n",
       "Torch Club (Massillon, OH)                                      2   \n",
       "Wonder Bar (Zanesville, OH)                                     1   \n",
       "Capitol Theatre (Lancaster, PA)                                 1   \n",
       "United States Theater                                           1   \n",
       "Twigg's Night Club (Akron, OH)                                  1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                  1   \n",
       "Terrace Gardens (Jamestown, NY)                                 1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                               1   \n",
       "Club DeLisa (Chicago, IL)                                       1   \n",
       "\n",
       "                                   max_span (days, delta: 14 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                  42   \n",
       "Torch Club (Massillon, OH)                                      17   \n",
       "Wonder Bar (Zanesville, OH)                                     17   \n",
       "Capitol Theatre (Lancaster, PA)                                  0   \n",
       "United States Theater                                            0   \n",
       "Twigg's Night Club (Akron, OH)                                   1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                   0   \n",
       "Terrace Gardens (Jamestown, NY)                                  0   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                0   \n",
       "Club DeLisa (Chicago, IL)                                        0   \n",
       "\n",
       "                                   max performers in a group (#, delta: 14 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                                 2   \n",
       "Torch Club (Massillon, OH)                                                     7   \n",
       "Wonder Bar (Zanesville, OH)                                                    8   \n",
       "Capitol Theatre (Lancaster, PA)                                                1   \n",
       "United States Theater                                                          1   \n",
       "Twigg's Night Club (Akron, OH)                                                 4   \n",
       "Kedzie (Chicago) (Chicago, IL)                                                 1   \n",
       "Terrace Gardens (Jamestown, NY)                                                1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                              1   \n",
       "Club DeLisa (Chicago, IL)                                                      1   \n",
       "\n",
       "                                  group_member_counters for venue (#, delta: 14 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                          {1: 2, 2: 1}    \n",
       "Torch Club (Massillon, OH)                                              {6: 1, 7: 1}    \n",
       "Wonder Bar (Zanesville, OH)                                                   {8: 1}    \n",
       "Capitol Theatre (Lancaster, PA)                                               {1: 1}    \n",
       "United States Theater                                                         {1: 1}    \n",
       "Twigg's Night Club (Akron, OH)                                                {4: 1}    \n",
       "Kedzie (Chicago) (Chicago, IL)                                                {1: 1}    \n",
       "Terrace Gardens (Jamestown, NY)                                               {1: 1}    \n",
       "Javo Jungle Club (Pittsburgh, PA)                                             {1: 1}    \n",
       "Club DeLisa (Chicago, IL)                                                     {1: 1}    \n",
       "\n",
       "                                   num_groups (#, delta: 31 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                  3   \n",
       "Torch Club (Massillon, OH)                                      2   \n",
       "Wonder Bar (Zanesville, OH)                                     1   \n",
       "Capitol Theatre (Lancaster, PA)                                 1   \n",
       "United States Theater                                           1   \n",
       "Twigg's Night Club (Akron, OH)                                  1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                  1   \n",
       "Terrace Gardens (Jamestown, NY)                                 1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                               1   \n",
       "Club DeLisa (Chicago, IL)                                       1   \n",
       "\n",
       "                                   max_span (days, delta: 31 days)  ...  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                  42  ...   \n",
       "Torch Club (Massillon, OH)                                      17  ...   \n",
       "Wonder Bar (Zanesville, OH)                                     17  ...   \n",
       "Capitol Theatre (Lancaster, PA)                                  0  ...   \n",
       "United States Theater                                            0  ...   \n",
       "Twigg's Night Club (Akron, OH)                                   1  ...   \n",
       "Kedzie (Chicago) (Chicago, IL)                                   0  ...   \n",
       "Terrace Gardens (Jamestown, NY)                                  0  ...   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                0  ...   \n",
       "Club DeLisa (Chicago, IL)                                        0  ...   \n",
       "\n",
       "                                   max performers in a group (#, delta: 93 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                                 2   \n",
       "Torch Club (Massillon, OH)                                                     7   \n",
       "Wonder Bar (Zanesville, OH)                                                    8   \n",
       "Capitol Theatre (Lancaster, PA)                                                1   \n",
       "United States Theater                                                          1   \n",
       "Twigg's Night Club (Akron, OH)                                                 4   \n",
       "Kedzie (Chicago) (Chicago, IL)                                                 1   \n",
       "Terrace Gardens (Jamestown, NY)                                                1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                              1   \n",
       "Club DeLisa (Chicago, IL)                                                      1   \n",
       "\n",
       "                                  group_member_counters for venue (#, delta: 93 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                                {2: 2}    \n",
       "Torch Club (Massillon, OH)                                              {6: 1, 7: 1}    \n",
       "Wonder Bar (Zanesville, OH)                                                   {8: 1}    \n",
       "Capitol Theatre (Lancaster, PA)                                               {1: 1}    \n",
       "United States Theater                                                         {1: 1}    \n",
       "Twigg's Night Club (Akron, OH)                                                {4: 1}    \n",
       "Kedzie (Chicago) (Chicago, IL)                                                {1: 1}    \n",
       "Terrace Gardens (Jamestown, NY)                                               {1: 1}    \n",
       "Javo Jungle Club (Pittsburgh, PA)                                             {1: 1}    \n",
       "Club DeLisa (Chicago, IL)                                                     {1: 1}    \n",
       "\n",
       "                                   num_groups (#, delta: 186 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                   2   \n",
       "Torch Club (Massillon, OH)                                       2   \n",
       "Wonder Bar (Zanesville, OH)                                      1   \n",
       "Capitol Theatre (Lancaster, PA)                                  1   \n",
       "United States Theater                                            1   \n",
       "Twigg's Night Club (Akron, OH)                                   1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                   1   \n",
       "Terrace Gardens (Jamestown, NY)                                  1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                1   \n",
       "Club DeLisa (Chicago, IL)                                        1   \n",
       "\n",
       "                                   max_span (days, delta: 186 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                   77   \n",
       "Torch Club (Massillon, OH)                                       17   \n",
       "Wonder Bar (Zanesville, OH)                                      17   \n",
       "Capitol Theatre (Lancaster, PA)                                   0   \n",
       "United States Theater                                             0   \n",
       "Twigg's Night Club (Akron, OH)                                    1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                    0   \n",
       "Terrace Gardens (Jamestown, NY)                                   0   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                 0   \n",
       "Club DeLisa (Chicago, IL)                                         0   \n",
       "\n",
       "                                   max performers in a group (#, delta: 186 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                                  2   \n",
       "Torch Club (Massillon, OH)                                                      7   \n",
       "Wonder Bar (Zanesville, OH)                                                     8   \n",
       "Capitol Theatre (Lancaster, PA)                                                 1   \n",
       "United States Theater                                                           1   \n",
       "Twigg's Night Club (Akron, OH)                                                  4   \n",
       "Kedzie (Chicago) (Chicago, IL)                                                  1   \n",
       "Terrace Gardens (Jamestown, NY)                                                 1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                               1   \n",
       "Club DeLisa (Chicago, IL)                                                       1   \n",
       "\n",
       "                                  group_member_counters for venue (#, delta: 186 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                                {2: 2}     \n",
       "Torch Club (Massillon, OH)                                              {6: 1, 7: 1}     \n",
       "Wonder Bar (Zanesville, OH)                                                   {8: 1}     \n",
       "Capitol Theatre (Lancaster, PA)                                               {1: 1}     \n",
       "United States Theater                                                         {1: 1}     \n",
       "Twigg's Night Club (Akron, OH)                                                {4: 1}     \n",
       "Kedzie (Chicago) (Chicago, IL)                                                {1: 1}     \n",
       "Terrace Gardens (Jamestown, NY)                                               {1: 1}     \n",
       "Javo Jungle Club (Pittsburgh, PA)                                             {1: 1}     \n",
       "Club DeLisa (Chicago, IL)                                                     {1: 1}     \n",
       "\n",
       "                                   num_groups (#, delta: 365 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                   1   \n",
       "Torch Club (Massillon, OH)                                       1   \n",
       "Wonder Bar (Zanesville, OH)                                      1   \n",
       "Capitol Theatre (Lancaster, PA)                                  1   \n",
       "United States Theater                                            1   \n",
       "Twigg's Night Club (Akron, OH)                                   1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                   1   \n",
       "Terrace Gardens (Jamestown, NY)                                  1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                1   \n",
       "Club DeLisa (Chicago, IL)                                        1   \n",
       "\n",
       "                                   max_span (days, delta: 365 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                  306   \n",
       "Torch Club (Massillon, OH)                                      290   \n",
       "Wonder Bar (Zanesville, OH)                                      17   \n",
       "Capitol Theatre (Lancaster, PA)                                   0   \n",
       "United States Theater                                             0   \n",
       "Twigg's Night Club (Akron, OH)                                    1   \n",
       "Kedzie (Chicago) (Chicago, IL)                                    0   \n",
       "Terrace Gardens (Jamestown, NY)                                   0   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                 0   \n",
       "Club DeLisa (Chicago, IL)                                         0   \n",
       "\n",
       "                                   max performers in a group (#, delta: 365 days)  \\\n",
       "Tiny's Chateau (Pottstown, PA)                                                  3   \n",
       "Torch Club (Massillon, OH)                                                     13   \n",
       "Wonder Bar (Zanesville, OH)                                                     8   \n",
       "Capitol Theatre (Lancaster, PA)                                                 1   \n",
       "United States Theater                                                           1   \n",
       "Twigg's Night Club (Akron, OH)                                                  4   \n",
       "Kedzie (Chicago) (Chicago, IL)                                                  1   \n",
       "Terrace Gardens (Jamestown, NY)                                                 1   \n",
       "Javo Jungle Club (Pittsburgh, PA)                                               1   \n",
       "Club DeLisa (Chicago, IL)                                                       1   \n",
       "\n",
       "                                  group_member_counters for venue (#, delta: 365 days)  \n",
       "Tiny's Chateau (Pottstown, PA)                                                {3: 1}    \n",
       "Torch Club (Massillon, OH)                                                   {13: 1}    \n",
       "Wonder Bar (Zanesville, OH)                                                   {8: 1}    \n",
       "Capitol Theatre (Lancaster, PA)                                               {1: 1}    \n",
       "United States Theater                                                         {1: 1}    \n",
       "Twigg's Night Club (Akron, OH)                                                {4: 1}    \n",
       "Kedzie (Chicago) (Chicago, IL)                                                {1: 1}    \n",
       "Terrace Gardens (Jamestown, NY)                                               {1: 1}    \n",
       "Javo Jungle Club (Pittsburgh, PA)                                             {1: 1}    \n",
       "Club DeLisa (Chicago, IL)                                                     {1: 1}    \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "metadata = {}\n",
    "\n",
    "df_grouped_dates = pd.DataFrame()\n",
    "\n",
    "venue_span_data = {}\n",
    "# Loop through each venue with adhering data\n",
    "for venue, row in df.groupby('Venue'):\n",
    "    d = {}\n",
    "    for days in [3, 14, 31, 93, 186, 365]:\n",
    "        all_dates = list(set(row.Date))\n",
    "        #print(venue, all_dates)\n",
    "        grouped_dates = group_dates(all_dates, delta=datetime.timedelta(days=days))\n",
    "        max_span = 0\n",
    "        max_performers_in_date_group = 0\n",
    "        group_member_counters = Counter()\n",
    "        for date_group in grouped_dates:\n",
    "            venue_span_data[str(date_group)] = {}\n",
    "            performers_in_date_group = []\n",
    "            last_day_in_date_group = max([datetime.datetime.strptime(x, '%Y-%m-%d') for x in date_group])\n",
    "            first_day_in_date_group = min([datetime.datetime.strptime(x, '%Y-%m-%d') for x in date_group])\n",
    "            datespan = (last_day_in_date_group - first_day_in_date_group).days\n",
    "            if datespan > max_span:\n",
    "                max_span = datespan\n",
    "            for performer in [get_performers_who_were_there(df, where=venue, when=x) for x in date_group]:\n",
    "                performers_in_date_group.extend(performer)\n",
    "            performers_in_date_group = list(set(performers_in_date_group))\n",
    "            if len(performers_in_date_group) > max_performers_in_date_group:\n",
    "                max_performers_in_date_group = len(performers_in_date_group)\n",
    "            group_member_counters[len(performers_in_date_group)] += 1\n",
    "            # print(venue, first_day_in_date_group, last_day_in_date_group, performers_in_date_group)\n",
    "        d[f'num_groups (#, delta: {days} days)'] = len(grouped_dates)\n",
    "        d[f'max_span (days, delta: {days} days)'] = max_span\n",
    "        d[f'max performers in a group (#, delta: {days} days)'] = max_performers_in_date_group\n",
    "        d[f'group_member_counters for venue (#, delta: {days} days)'] = group_member_counters\n",
    "    s = pd.Series(d, name=venue)\n",
    "    df_grouped_dates = df_grouped_dates.append(s)\n",
    "    dtype = {key: int for key in [x for x in d.keys() if not 'group_member_counters for venue' in x]}\n",
    "    df_grouped_dates = df_grouped_dates.astype(dtype)\n",
    "\n",
    "display(Markdown('### Sample of 10 random points in the dataset\\n\\nEach span (`3 days`, `14 days`, `31 days`, `93 days`, `186 days`, and `365 days`) has a `num_groups` column, a `max_span` column, and a `max performers` column.'))\n",
    "df_grouped_dates[list(d.keys())].sample(10).sort_values('num_groups (#, delta: 3 days)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['grouped_dates'] = df_grouped_dates[list(d.keys())].T.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network grouped data\n",
    "\n",
    "Setting up networks with nodes and edges for each of the day spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "networks = {}\n",
    "\n",
    "venue_count = len(group_data_dict)\n",
    "i = 0\n",
    "for venue, data in group_data_dict.items():\n",
    "    i+=1\n",
    "    for grouped_by, data2 in data.items():\n",
    "        clear_output(wait=True)\n",
    "        log(f'Generating network for {grouped_by}.')\n",
    "        log(f'   [{i}/{venue_count}] processing venue {venue}...')\n",
    "        if not grouped_by in networks:\n",
    "            networks[grouped_by] = nx.Graph()\n",
    "            networks[grouped_by].generated = datetime.datetime.now()\n",
    "\n",
    "        for date_group_id, data3 in data2.items():\n",
    "            if len(data3['performers']) > 1:\n",
    "                performers = data3['performers']\n",
    "                dates = data3['dates']\n",
    "                revues = data3['revues']\n",
    "                cities = data3['cities']\n",
    "                for performer in performers:\n",
    "                    for target in [x for x in performers if not x == performer]:\n",
    "                        edge = (performer, target)\n",
    "                        if not edge in networks[grouped_by].edges:\n",
    "                            networks[grouped_by].add_edges_from([edge], coLocated={})\n",
    "                        if not venue in networks[grouped_by].edges[edge]['coLocated']:\n",
    "                            networks[grouped_by].edges[edge]['coLocated'][venue] = []\n",
    "                        if not dates in networks[grouped_by].edges[edge]['coLocated'][venue]:\n",
    "                            networks[grouped_by].edges[edge]['coLocated'][venue].append(dates)\n",
    "                        \n",
    "                        if not 'revues' in networks[grouped_by].edges[edge]:\n",
    "                            networks[grouped_by].edges[edge]['revues'] = []\n",
    "                        if not revues in networks[grouped_by].edges[edge]['revues']:\n",
    "                            networks[grouped_by].edges[edge]['revues'].append(revues)\n",
    "\n",
    "                        if not 'cities' in networks[grouped_by].edges[edge]:\n",
    "                            networks[grouped_by].edges[edge]['cities'] = []\n",
    "                        if not cities in networks[grouped_by].edges[edge]['cities']:\n",
    "                            networks[grouped_by].edges[edge]['cities'].append(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def drop_unnamed(n):\n",
    "    return not 'unnamed' in n.lower()\n",
    "\n",
    "_networks = {}\n",
    "\n",
    "for key in networks.keys():\n",
    "    _networks[key] = copy.deepcopy(networks[key])\n",
    "    _networks[f'{key}-no-unnamed-performers'] = nx.subgraph_view(_networks[key], filter_node=drop_unnamed)\n",
    "    _networks[f'{key}-no-unnamed-performers'].generated = datetime.datetime.now()\n",
    "    \n",
    "networks = _networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge meta/weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in networks.keys():\n",
    "    for edge in list(networks[key].edges):\n",
    "        networks[key].edges[edge]['weights'] = {}\n",
    "        for co_located, date_groups in networks[key].edges[edge]['coLocated'].items():\n",
    "            networks[key].edges[edge]['weights']['dateGroups'] = len(date_groups)\n",
    "        networks[key].edges[edge]['weights']['venues'] = len(networks[key].edges[edge]['coLocated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node meta/comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up functions for getting node meta information\n",
    "\n",
    "Node meta information = things like comments, images, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_data(df, category=None):\n",
    "    meta_data = {\n",
    "        'performers': {},\n",
    "        'venues': {},\n",
    "        'cities': {},\n",
    "        'revues': {}\n",
    "    }\n",
    "\n",
    "    MAP = {\n",
    "        'performers': {\n",
    "            'cleaned_row_name': 'Performer',\n",
    "            'MAPPING': {\n",
    "                'comments': 'Comment on node: performer',\n",
    "                'legal_names': 'Legal name',\n",
    "                'alleged_ages': 'Alleged age',\n",
    "                'assumed_birth_years': 'Assumed birth year',\n",
    "                'images': 'Has image',\n",
    "                'exotic_dancer': 'Exotic/erotic/oriental dancer/Gypsy',\n",
    "                'fan_dancer': 'Fan dancer/Sally Rand',\n",
    "                'blackface': 'Blackface',\n",
    "                'sepia': 'Sepia',\n",
    "            }\n",
    "        },\n",
    "        'cities': {\n",
    "            'cleaned_row_name': 'City',\n",
    "            'MAPPING': {\n",
    "                'comments': 'Comment on node: city'\n",
    "            }\n",
    "        },\n",
    "        'venues': {\n",
    "            'cleaned_row_name': 'Venue',\n",
    "            'MAPPING': {\n",
    "                'comments': 'Comment on node: venue'\n",
    "            }\n",
    "        },\n",
    "        'revues': {\n",
    "            'cleaned_row_name': 'Revue',\n",
    "            'MAPPING': {\n",
    "                'comments': 'Comment on edge: revue'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ### No need to change anything below\n",
    "\n",
    "    for meta_data_category, d in MAP.items():\n",
    "        if category and not meta_data_category == category:\n",
    "            continue\n",
    "        \n",
    "        log(f'Fetching node meta information for {meta_data_category}...')\n",
    "        for ix, row in df.iterrows():\n",
    "            if not row[d['cleaned_row_name']] in meta_data[meta_data_category]:\n",
    "                meta_data[meta_data_category][row[d['cleaned_row_name']]] = {}\n",
    "\n",
    "            for key, column_name in d['MAPPING'].items():\n",
    "                if not key in meta_data[meta_data_category][row[d['cleaned_row_name']]]:\n",
    "                    meta_data[meta_data_category][row[d['cleaned_row_name']]][key] = []\n",
    "\n",
    "                if row[column_name]:\n",
    "                    source = row['Source']\n",
    "                    content = row[column_name]\n",
    "                    if isinstance(content, str) and content.lower() == 'true':\n",
    "                        content = True\n",
    "\n",
    "                    meta_data[meta_data_category][row[d['cleaned_row_name']]][key].append({\n",
    "                        'source': source,\n",
    "                        'content': content\n",
    "                    })\n",
    "    \n",
    "    return meta_data\n",
    "\n",
    "def get_meta(df=None, category=None):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        log('Building new clean data for node meta information...')\n",
    "        df = get_raw_data(verbose=False)\n",
    "        df = filter_data(df, max_date=None, min_date=None, verbose=False)\n",
    "        df = clean_data(df, drop_cols=['Venue'], verbose=False)\n",
    "    \n",
    "    all_meta = get_meta_data(df, category=category)\n",
    "    \n",
    "    if not category:\n",
    "        return all_meta\n",
    "    \n",
    "    return all_meta[category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get  node meta data from sheet\n",
    "\n",
    "`node_meta` fetches the information, then we loop through each network and add the meta data to each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<font color=\"green\">[23:39:52] Building new clean data for node meta information...</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e165a87ee939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_meta\u001b[0m \u001b[0;31m# adding all the meta data for nodes and edges to metadata['content']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1d4393800e99>\u001b[0m in \u001b[0;36mget_meta\u001b[0;34m(df, category)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building new clean data for node meta information...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Venue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2da46744da33>\u001b[0m in \u001b[0;36mget_raw_data\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://docs.google.com/spreadsheets/d/e/2PACX-1vT0E0Y7txIa2pfBuusA1cd8X5OVhQ_D0qZC8D40KhTU3xB7McsPR2kuB7GH6ncmNT3nfjEYGbscOPp0/pub?gid=0&single=true&output=csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Fix basic stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'—'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# though mypy handling of conditional imports is difficult.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# TODO: fsspec can also handle HTTP via requests, but leaving this unchanged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "all_meta = get_meta()\n",
    "metadata['content'] = all_meta # adding all the meta data for nodes and edges to metadata['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add manual meta information to each network's nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in networks.keys():\n",
    "    nx.set_node_attributes(networks[key], all_meta['performers'])\n",
    "    \n",
    "log(f'Finished setting meta information about performers on all {len(networks)} networks.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get automatic network meta information per node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_nodes_per_node(G):\n",
    "    return {node: sorted(nx.bfs_tree(G, node, reverse=False).nodes) for node in G.nodes}\n",
    "\n",
    "def get_unique_networks(connected_nodes_per_node):\n",
    "    if isinstance(connected_nodes_per_node, dict):\n",
    "        pass # fine!\n",
    "    elif isinstance(connected_nodes_per_node, nx.classes.graph.Graph):\n",
    "        connected_nodes_per_node = get_connected_nodes_per_node(connected_nodes_per_node)\n",
    "    else:\n",
    "        raise RuntimeError('connected_nodes_per_node provided must be either a dictionary of nodes connected together or a networkx Graph object.')\n",
    "        \n",
    "    unique_networks = []\n",
    "    for network in list(connected_nodes_per_node.values()):\n",
    "        if not network in unique_networks:\n",
    "            unique_networks.append(network)\n",
    "    return unique_networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data to each network's nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in networks.keys():\n",
    "    unique_networks = get_unique_networks(networks[key])\n",
    "    log(f'Adding connected network data for network `{key}` ({len(unique_networks)} unique networks found)...')\n",
    "\n",
    "    for network_id, unique_network in enumerate(unique_networks, start=1):\n",
    "        for performer in unique_network:\n",
    "            networks[key].nodes[performer]['connected'] = {\n",
    "                'network': {\n",
    "                    'nodes': [x for x in unique_network if not x == performer],\n",
    "                    'network_id': network_id\n",
    "                }\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get communities per node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_community_dicts(*args):\n",
    "    _ = {}\n",
    "    for dictionary in args:\n",
    "        for performer, data in dictionary.items():\n",
    "            if not performer in _:\n",
    "                _[performer] = {}\n",
    "            for key, value in data.items():\n",
    "                if not key in _[performer]:\n",
    "                    if isinstance(value, dict):\n",
    "                        _[performer][key] = {}\n",
    "                    else:\n",
    "                        raise NotImplemented('Nope')\n",
    "                for key2, value2 in value.items():\n",
    "                    if not key2 in _[performer][key]:\n",
    "                        _[performer][key][key2] = value2\n",
    "                    else:\n",
    "                        raise NotImplemented('This should not happen')\n",
    "\n",
    "    return _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dictionaries with all the community information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain\n",
    "\n",
    "for key in networks.keys():\n",
    "    log(f'Setting community data on nodes in network {key}...')\n",
    "    \n",
    "    # Run Louvain algorithm\n",
    "    louvain = community_louvain.best_partition(networks[key])\n",
    "    louvain = {performer: {'modularities': {'Louvain': community_number}} for performer, community_number in louvain.items()}\n",
    "    \n",
    "    # Run Clauset Newman Moore algorithm\n",
    "    c = nx.community.greedy_modularity_communities(networks[key])\n",
    "    clauset_newman_moore = {performer: {'modularities': {'Clauset-Newman-Moore': community_number}} for community_number, list_of_performers in enumerate(c, start=1) for performer in list_of_performers}\n",
    "    \n",
    "    # Run Girvan Newman algorithm\n",
    "    '''\n",
    "    # TODO: This won't work\n",
    "    gn = nx.community.girvan_newman(networks[key])\n",
    "    first_girvan_newman_iteration = next(gn)\n",
    "    girvan_newman_groups = {group: names for group, names in enumerate([list(x) for x in first_girvan_newman_iteration], start=1)}\n",
    "    '''\n",
    "    \n",
    "    community_dicts = merge_community_dicts(louvain, clauset_newman_moore)\n",
    "\n",
    "    nx.set_node_attributes(networks[key], community_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set centrality data per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in networks.keys():\n",
    "    log(f'Setting centrality data on nodes in network {key}...')\n",
    "    for performer in networks[key].nodes:\n",
    "        networks[key].nodes[performer]['centralities'] = {}\n",
    "\n",
    "    log(f' --> `degree_centrality`')\n",
    "    for performer, degree in nx.degree_centrality(networks[key]).items():\n",
    "        networks[key].nodes[performer]['centralities']['degree_centrality_100x'] = round(degree*100, 6)\n",
    "\n",
    "    log(f' --> `betweenness_centrality`')\n",
    "    for performer, degree in nx.betweenness_centrality(networks[key], k=len(networks[key].nodes)).items():\n",
    "        networks[key].nodes[performer]['centralities']['betweenness_centrality_100x'] = round(degree*100, 6)\n",
    "\n",
    "    log(f' --> `eigenvector_centrality`')\n",
    "    for performer, degree in nx.eigenvector_centrality(networks[key], max_iter=100, weight='weight').items():\n",
    "        networks[key].nodes[performer]['centralities']['eigenvector_centrality_100x'] = round(degree*100, 6)\n",
    "\n",
    "    # TODO: Katz centrality keeps failing within 1000 iterations :/\n",
    "    log(f' --> `katz_centrality`')\n",
    "    #try:\n",
    "    #    for performer, degree in nx.katz_centrality(networks[key]).items():\n",
    "    #        networks[key].nodes[performer]['centralities']['katz_centrality_100x'] = round(degree*100, 6)\n",
    "    #except nx.exception.PowerIterationFailedConvergence as e:\n",
    "    #    print(f'Katz Centrality failed: {e}')\n",
    "\n",
    "    log(f' --> `closeness_centrality`')\n",
    "    for performer, degree in nx.closeness_centrality(networks[key]).items():\n",
    "        networks[key].nodes[performer]['centralities']['closeness_centrality_100x'] = round(degree*100, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set degree per node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degrees(G, node):\n",
    "    indegree = sum([1 for edge in G.edges if edge[0] == node])\n",
    "    outdegree = sum([1 for edge in G.edges if edge[1] == node])\n",
    "    degree = indegree + outdegree\n",
    "    \n",
    "    return {\n",
    "        'indegree': indegree,\n",
    "        'outdegree': outdegree,\n",
    "        'degree': degree\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data to each network's nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in networks.keys():\n",
    "    log(f'Setting degree data on {len(networks[key].nodes)} nodes in network {key}...')\n",
    "    degrees = {node: {'degrees': get_degrees(networks[key], node)} for node in networks[key].nodes}\n",
    "    nx.set_node_attributes(networks[key], degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional node and edge metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, network in networks.items():    \n",
    "    for node in networks[key].nodes:\n",
    "        networks[key].nodes[node]['node_id'] = slugify(node)\n",
    "        networks[key].nodes[node]['category'] = 'performer'\n",
    "        networks[key].nodes[node]['display'] = node\n",
    "    \n",
    "    for edge in networks[key].edges:\n",
    "        networks[key].edges[edge]['edge_id'] = slugify(f'{edge[0]}-{edge[1]}')\n",
    "        networks[key].edges[edge]['comments'] = [] # TODO\n",
    "        networks[key].edges[edge]['general_comments'] = [] # TODO\n",
    "        \n",
    "        # setup 'found' property of edges\n",
    "        networks[key].edges[edge]['found'] = []\n",
    "        for _, dates in networks[key].edges[edge]['coLocated'].items():\n",
    "            for datelist in dates:\n",
    "                for date in datelist:\n",
    "                    if not date in networks[key].edges[edge]['found']:\n",
    "                        networks[key].edges[edge]['found'].append(date)\n",
    "                        \n",
    "        # setup 'comments' for all of the involved venues, cities, revues\n",
    "        networks[key].edges[edge]['comments'] = {\n",
    "            'venues': {},\n",
    "            'cities': {},\n",
    "            'revues': {}\n",
    "        }\n",
    "        \n",
    "    networks[grouped_by].finished = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in networks:\n",
    "    file_name = f'co-occurrence-{key}.json'\n",
    "    \n",
    "    data = nx.node_link_data(networks[key])\n",
    "    data['createdDate'] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    diff = datetime.datetime.now() - networks[key].generated\n",
    "    data['timeToCreate'] = {\n",
    "        'minutes': diff.seconds//60,\n",
    "        'seconds': diff.seconds%60,\n",
    "        'totalInSeconds': diff.seconds\n",
    "    }\n",
    "    data['days'] = re.findall(r'\\d+', key)[0]\n",
    "\n",
    "    with open('./docs/data/'+file_name, 'w+') as fp:\n",
    "        json.dump(obj=data, fp=fp)\n",
    "        log(f'Saved {fp.name} (took {round((data[\"timeToCreate\"][\"totalInSeconds\"]/60), 2)} minutes to generate)')\n",
    "        \n",
    "with open('./docs/data/co-occurrence-_metadata.json', 'w+') as fp:\n",
    "    json.dump(obj=metadata, fp=fp)\n",
    "    log(f'Saved metadata file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to other formats (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gephi\n",
    "\n",
    "The following part of the script removes all the metadata from the graph (which causes trouble with Gephi's file format) and generates \"naked\" network files for each of the co-occurrence graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gexf_networks = copy.deepcopy(networks)\n",
    "\n",
    "for key in gexf_networks:\n",
    "    for node in gexf_networks[key].nodes:\n",
    "        for k in ['comments', 'legal_names', 'alleged_ages', 'assumed_birth_years', 'images', 'exotic_dancer', 'fan_dancer', 'blackface', 'sepia']:\n",
    "            if k in gexf_networks[key].nodes[node]:\n",
    "                del gexf_networks[key].nodes[node][k]\n",
    "    for edge in gexf_networks[key].edges:\n",
    "        for k in ['coLocated', 'revues', 'cities', 'weights', 'edge_id', 'comments', 'general_comments', 'found']:\n",
    "            if k in gexf_networks[key].edges[edge]:\n",
    "                del gexf_networks[key].edges[edge][k]\n",
    "                \n",
    "for key in gexf_networks:\n",
    "    file_name = f'gephi/co-occurrence-{key}.gexf'\n",
    "    \n",
    "    nx.write_gexf(gexf_networks[key], file_name)\n",
    "    log(f'Saved {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "415.208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
